{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLOT FOR THR, LATENCY FOR POWER MODE TESTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Globals and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLATFORM=\"Orin Nano\"\n",
    "\n",
    "#POWER_MODES={'PM0': {},'PM1': {},'PM2': {}}  #{'PM0': {},'PM1': {},'PM2': {}}   \n",
    "POWER_MODES={'LVL5': {},'LVL3': {},'LVL0': {}} \n",
    "#POWER_MODES={'DYNAMIC': {},'STATIC': {}} \n",
    "\n",
    "#PATH_TO_MD=\"../outputs/table_outputs/evaluaciones_adicionales/orin_agx/jetson_orin_agx_power_mode_test.md\"\n",
    "PATH_TO_MD=\"../outputs/table_outputs/evaluaciones_adicionales/orin_nano/jetson_orin_nano_optimization_level_test.md\"\n",
    "#PATH_TO_MD=\"../outputs/table_outputs/evaluaciones_adicionales/orin_nano/jetson_orin_nano_static_vs_dynamic_test.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_data_for_throughput(file_content):\n",
    "\n",
    "    # la idea de esta funcion es agrupar el throupgut y la confianza en data_summary para cada plataforma, para poder luego hacer el print del grafico de los througputs\n",
    "    power_mode_datas = file_content.split(f'# {PLATFORM} ')[1:]  # Divide por power mode\n",
    "    data_summary = {}\n",
    "\n",
    "    # Procesar datos principales para batch size 1 y añadir inf/s de batch size 256 cuando corresponda\n",
    "    for power_mode_data in power_mode_datas:\n",
    "        power_mode_saved = power_mode_data.splitlines()[0].strip()\n",
    "        models_data = power_mode_data.split('## ')[1:]  # Divide por modelo y batch size, ignorando el primer split que estaría vacío\n",
    "        for model_section in models_data:\n",
    "            lines = model_section.split('\\n')\n",
    "            model_name_batch_size = lines[0].strip()\n",
    "            model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "            batch_size = int(batch_size_info.strip())\n",
    "\n",
    "            table_data = [line for line in lines if '|' in line and 'Model' not in line]\n",
    "\n",
    "            for data in table_data:\n",
    "                if not all(char == '-' for char in data.replace('|', '').strip()):\n",
    "                    cols = [col.strip() for col in data.split('|')]\n",
    "                    if len(cols) > 1:\n",
    "                        model_variant = cols[1]\n",
    "                        inf_s_str = (cols[2].split(' ')[0].replace('.','')).replace(',','.')\n",
    "                        inf_s = float(inf_s_str)\n",
    "                        confianza_str_minus = (cols[2].split(' ')[3].replace('.','')).replace(',','.').replace('-','')\n",
    "                        confianza_str_plus = (cols[2].split(' ')[2].replace('.','')).replace(',','.').replace('+','')\n",
    "                        confianza = max(float(confianza_str_minus),float(confianza_str_plus))\n",
    "                        \n",
    "                        if power_mode_saved not in data_summary:\n",
    "                            data_summary[power_mode_saved] = {}\n",
    "                        if model_name not in data_summary[power_mode_saved]:\n",
    "                            data_summary[power_mode_saved][model_name] = {}\n",
    "                        if model_variant not in data_summary[power_mode_saved][model_name]:\n",
    "                            data_summary[power_mode_saved][model_name][model_variant] = {}\n",
    "                        data_summary[power_mode_saved][model_name][model_variant][batch_size] = inf_s, confianza\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar los datos de throughput (thr)\n",
    "def plot_thr(data):\n",
    "    # Recorrer cada red neuronal\n",
    "    for network, optimizations in list(data.values())[0].items():\n",
    "        # Recorrer cada optimización\n",
    "        for optimization in optimizations.keys():\n",
    "            plt.rcParams.update({'font.size': 14})  # Ajustar el tamaño de la fuente\n",
    "            plt.figure(figsize=(5, 3.5)).tight_layout()\n",
    "\n",
    "            # Graficar los resultados para cada modo de potencia\n",
    "            for power_mode, networks in data.items():\n",
    "                if network not in networks:\n",
    "                    continue  # Saltar si la red no está en este modo de potencia\n",
    "\n",
    "                optim_data = networks[network][optimization]  # Datos de la optimización específica\n",
    "                batch_sizes_sorted = sorted(optim_data.keys())  # Ordenar los tamaños de lote\n",
    "                infs = [optim_data[bs][0] for bs in batch_sizes_sorted]  # Obtener los valores de inferencias\n",
    "\n",
    "                # Graficar los resultados\n",
    "                plt.plot(batch_sizes_sorted, infs, marker='o', label=f'{power_mode}')\n",
    "            \n",
    "            # Configurar los detalles del gráfico\n",
    "            plt.title(f'Jetson {PLATFORM}, {network} - {optimization}')\n",
    "            plt.xlabel('Batch Size')\n",
    "            plt.ylabel('Throughput [inf/s]')\n",
    "            plt.legend(title='Power Mode')\n",
    "            plt.grid(True)\n",
    "            plt.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "            plt.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "            plt.minorticks_on()\n",
    "            plataforma = PLATFORM.split(' ')[1]\n",
    "            plt.savefig(f'Thr_{plataforma}_{network}_{optimization}.pdf', format='pdf', bbox_inches='tight')  # Guardar la figura (opcional)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_thrs_red_by_power_mode(data):\n",
    "    for network, optimizations in list(data.values())[0].items():\n",
    "        plt.rcParams.update({'font.size': 14})  # Ajustar el tamaño de la fuente\n",
    "        num_power_modes = len(data.keys())\n",
    "        \n",
    "        # Encontrar el valor máximo de throughput (thr) para esta red\n",
    "        max_thr = 0\n",
    "        for power_mode, networks in data.items():\n",
    "            if network not in networks:\n",
    "                continue\n",
    "            for optimization in optimizations.keys():\n",
    "                optim_data = networks[network][optimization]\n",
    "                batch_sizes_sorted = sorted(optim_data.keys())\n",
    "                infs = [optim_data[bs][0] for bs in batch_sizes_sorted]\n",
    "                max_thr = max(max_thr, max(infs))\n",
    "\n",
    "        # Crear subplots en una fila con un subplot por \"power mode\"\n",
    "        fig, axes = plt.subplots(1, num_power_modes, figsize=(7 * num_power_modes, 5))\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.85, wspace=0.05)  # Espacio adicional en la parte superior para la leyenda\n",
    "\n",
    "        for idx, (power_mode, ax) in enumerate(zip(data.keys(), axes)):\n",
    "            # Graficar los resultados para cada optimización dentro de este modo de potencia\n",
    "            networks = data[power_mode]\n",
    "            if network not in networks:\n",
    "                continue  # Saltar si la red no está en este modo de potencia\n",
    "            \n",
    "            for optimization in optimizations.keys():\n",
    "                optim_data = networks[network][optimization]  # Datos de la optimización específica\n",
    "                batch_sizes_sorted = sorted(optim_data.keys())  # Ordenar los tamaños de lote\n",
    "                infs = [optim_data[bs][0] for bs in batch_sizes_sorted]  # Obtener los valores de inferencias\n",
    "\n",
    "                # Graficar los resultados en el subplot correspondiente\n",
    "                ax.plot(batch_sizes_sorted, infs, marker='o', label=f'{optimization}')\n",
    "            \n",
    "            # Configurar los detalles del subplot\n",
    "            ax.set_title(f'{power_mode} - {network}')\n",
    "            ax.set_xlabel('Batch Size')\n",
    "            \n",
    "            # Establecer el límite superior del eje Y al máximo valor de throughput\n",
    "            ax.set_ylim(0, max_thr + 10)\n",
    "            ax.set_xlim(0, 270)\n",
    "            # Solo el primer subplot tiene el label del eje Y\n",
    "            if idx == 0:\n",
    "                ax.set_ylabel('Throughput [inf/s]')\n",
    "            else:\n",
    "                ax.set_ylabel('')  # No mostrar el label del eje Y\n",
    "                ax.tick_params(labelleft=False)  # No mostrar los valores del eje Y\n",
    "\n",
    "            ax.grid(True)\n",
    "            ax.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "            ax.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "            ax.minorticks_on()\n",
    "\n",
    "        # Agregar leyenda en la parte superior fuera de los gráficos\n",
    "        handles, labels = ax.get_legend_handles_labels()  # Obtener las leyendas de los últimos subplots\n",
    "        fig.legend(handles, labels, loc='upper center', ncol=len(labels))\n",
    "\n",
    "        plataforma = PLATFORM.split(' ')[1]\n",
    "        #plt.suptitle(f'Jetson {PLATFORM}, {network}')  # Título general de la figura\n",
    "        plt.savefig(f'Thr_{plataforma}_{network}.pdf', format='pdf', bbox_inches='tight')  # Guardar la figura (opcional)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para leer los datos del archivo .md considerando solo batch size 1\n",
    "def read_data_from_md_for_latency(file_path):\n",
    "    data = {}\n",
    "    current_pm = None\n",
    "    current_network = None\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        for line in lines:\n",
    "            # Detectar el Power Mode\n",
    "            if line.startswith(f'# {PLATFORM}'):\n",
    "                current_pm = line.strip().split()[-1]\n",
    "                if current_pm not in POWER_MODES:\n",
    "                    POWER_MODES[current_pm] = {}  # Añadir a POWER_MODES si no está presente\n",
    "            \n",
    "            # Detectar el nombre de la red y el batch size\n",
    "            network_match = re.match(r'## (\\w+) bs (\\d+)', line)\n",
    "            if network_match:\n",
    "                current_network = network_match.group(1)\n",
    "                batch_size = int(network_match.group(2))\n",
    "                \n",
    "                # Continuar solo si el batch size es 1\n",
    "                if batch_size != 1:\n",
    "                    current_network = None  # Ignorar este bloque si no es batch size 1\n",
    "                    continue\n",
    "            \n",
    "            # Leer los datos de la tabla si el batch size es 1\n",
    "            table_match = re.match(r'\\| (\\w+)\\s+\\|\\s+[\\d.,]+.*?\\|\\s+([\\d.,/ ]+)', line)\n",
    "            if table_match and current_pm and current_network:\n",
    "                model = table_match.group(1)\n",
    "                latency_str = table_match.group(2).split('/')[0].strip()\n",
    "                latency_max_str =  table_match.group(2).split('/')[1].strip()\n",
    "                \n",
    "                # Convertir la latencia a flotante\n",
    "                try:\n",
    "                    latency = float(latency_str.replace(',', '.'))\n",
    "                    latency_max = float(latency_max_str.replace(',', '.'))\n",
    "                except ValueError:\n",
    "                    print(f\"Error de conversión de latencia: '{latency_str}' en el modelo '{model}'\")\n",
    "                    continue\n",
    "                \n",
    "                # Organizar los datos en el diccionario\n",
    "                if model not in data:\n",
    "                    data[model] = {pm: {} for pm in POWER_MODES.keys()}\n",
    "                data[model][current_pm][current_network] = (latency,latency_max)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para graficar los datos\n",
    "def plot_model_latency(model_name, model_data):\n",
    "    plt.rcParams.update({'font.size': 14})  # Ajustar el tamaño de la fuente\n",
    "    plt.figure(figsize=(5, 3.5)).tight_layout()\n",
    "\n",
    "    networks = list(model_data[next(iter(POWER_MODES))].keys())  # Listado de redes\n",
    "\n",
    "    # Crear listas de latencias para cada modo de energía definido en POWER_MODES\n",
    "    latencies_by_pm = {pm: [model_data[pm].get(net, 0) for net in networks] for pm in POWER_MODES.keys()}\n",
    "\n",
    "    # Crear gráfico de barras\n",
    "    bar_width = 0.25\n",
    "    index = range(len(networks))\n",
    "\n",
    "    # Desplazar las barras para cada modo de energía\n",
    "    for i, (pm, latencies) in enumerate(latencies_by_pm.items()):\n",
    "        plt.bar([x + i * bar_width for x in index], latencies, bar_width, label=f'Power Mode {pm}')\n",
    "\n",
    "    plt.title(f'Jetson {PLATFORM}, {model_name}')\n",
    "    plt.xlabel('Network')\n",
    "    plt.ylabel('Latency (ms)')\n",
    "    plt.xticks([i + (len(POWER_MODES) - 1) * bar_width / 2 for i in index], networks)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "    plt.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "    plt.minorticks_on()\n",
    "    # Guardar el gráfico como PDF con el nombre del modelo\n",
    "    plataforma = PLATFORM.split(' ')[1]\n",
    "    plt.savefig(f'latency_{plataforma}_{model_name}.pdf', format='pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_latency_by_power_mode(data):\n",
    "    plt.rcParams.update({'font.size': 14})  # Ajustar el tamaño de la fuente\n",
    "\n",
    "    # Asumiendo que todas las redes y optimizaciones están presentes en todos los modos de potencia\n",
    "    sample = next(iter(data.values()))\n",
    "    power_modes = list(sample.keys())  # Listado de power modes\n",
    "    num_power_modes = len(power_modes)\n",
    "    models = list(data.keys())  # Lista de vanilla, fp32, fp16 e int8\n",
    "    networks = list(sample[next(iter(sample))].keys())  # Listado de optimizaciones\n",
    "    \n",
    "    # Calcular la latencia máxima para establecer los límites del eje Y\n",
    "    max_latency = 0\n",
    "    for model_data in data.values():\n",
    "        for power_mode_data in model_data.values():\n",
    "            for avg, max_ in power_mode_data.values():\n",
    "                max_latency = max(max_latency, max_)\n",
    "    \n",
    "    # Crear subplots en una fila con un subplot por cada \"power mode\"\n",
    "    fig, axes = plt.subplots(1, num_power_modes, figsize=(7 * num_power_modes, 5))\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.85,wspace=0.05)  # Ajustar el espacio horizontal entre subplots\n",
    "\n",
    "    bar_width = 0.15  # Ajuste del ancho de las barras para múltiples redes\n",
    "    index = range(len(networks))  # Ahora las optimizaciones estarán en el eje X\n",
    "\n",
    "    for i, power_mode in enumerate(power_modes):\n",
    "        ax = axes[i]  # Seleccionar el subplot correcto\n",
    "        for idx, model in enumerate(models):\n",
    "            model_data = data[model]\n",
    "            if power_mode in model_data:\n",
    "                latencies_avg = [model_data[power_mode][network][0] for network in networks]  # Obtener latencia promedio por optimización\n",
    "                latencies_max = [model_data[power_mode][network][1] - model_data[power_mode][network][0] for network in networks]  # Calcular error (latencia_max - latencia_avg)\n",
    "                y_errors = np.array([np.zeros(len(latencies_avg)), latencies_max])\n",
    "                # Graficar las barras con barras de error, usando el color de la barra para las líneas de error\n",
    "                bars = ax.bar([x + idx * bar_width for x in index], latencies_avg, bar_width, yerr=y_errors, \n",
    "                              label=f'{model}', capsize=5, ecolor='black',  # `ecolor` se ajustará más adelante\n",
    "                              error_kw={'elinewidth': 1.5})  # Grosor de las líneas de error\n",
    "\n",
    "                # Ajustar el color de las barras de error para que coincida con la barra\n",
    "                for bar, err, avg in zip(bars, latencies_max, latencies_avg):\n",
    "                    bar.set_edgecolor(bar.get_facecolor())  # Asegurar que el borde de la barra sea del mismo color\n",
    "                    ax.errorbar(bar.get_x() + bar_width / 2, avg, yerr=err, fmt='none', \n",
    "                                ecolor=bar.get_facecolor(), capsize=5)  # Hacer la barra de error del color de la barra\n",
    "\n",
    "        # Configurar los detalles del subplot\n",
    "        ax.set_title(f'{power_mode}')\n",
    "        #ax.set_xlabel('Network')\n",
    "        ax.set_xticks([i + (len(models) - 1) * bar_width / 2 for i in index])\n",
    "        ax.set_xticklabels(networks)\n",
    "\n",
    "        # Ajustar el límite del eje Y a la latencia máxima\n",
    "        ax.set_ylim(0, max_latency * 1.1)  # Agregar un 10% extra para margen\n",
    "\n",
    "        # Solo mostrar el label y la numeración del eje Y en el primer gráfico\n",
    "        if i == 0:\n",
    "            ax.set_ylabel('Latencia [ms]')\n",
    "            # Leyenda con los nombres de las redes\n",
    "            #ax.legend()\n",
    "        else:\n",
    "            ax.set_yticklabels([])  # Ocultar etiquetas del eje Y\n",
    "\n",
    "        ax.grid(True)\n",
    "        ax.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "        ax.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "        ax.minorticks_on()\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Obtener las leyendas de los últimos subplots\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=len(labels))\n",
    "    plataforma = PLATFORM.split(\" \")[1]  # Reemplaza esto con la variable que corresponda\n",
    "    plt.savefig(f'latency_{plataforma}.pdf', format='pdf', bbox_inches='tight')  # Guardar la figura\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotea el Thr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo .md\n",
    "file_path = PATH_TO_MD\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "data_thr = parse_markdown_data_for_throughput(data)\n",
    "plot_thrs_red_by_power_mode(data_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta del archivo .md\n",
    "file_path = PATH_TO_MD\n",
    "# Leer los datos del archivo .md\n",
    "data = read_data_from_md_for_latency(file_path)\n",
    "print(data)\n",
    "plot_model_latency_by_power_mode(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
