{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE RESULTADOS\n",
    "\n",
    "## globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../outputs/table_outputs/rtx2060/RTX2060MaxQ_dynamic_op.md'\n",
    "name = 'rtx_2060'\n",
    "name_titulo = 'RTX 2060'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(data):\n",
    "\n",
    "\n",
    "    # genera la tabla presente en los antecedentes de la tesis\n",
    "\n",
    "\n",
    "    latex_header_1 = r\"\"\"\n",
    "\\begin{table}[t]\n",
    "    \\centering\n",
    "    \\footnotesize\n",
    "    \\caption{\"\"\"\n",
    "    latex_header_2 = r\"\"\"}\n",
    "    \\begin{tabular}{@{}clccccccccccc@{}}\n",
    "    \\toprule\n",
    "    & & \\multicolumn{2}{c}{Latency {[}ms{]}} &  & Thr. {[}inf/s{]} &  \\multicolumn{3}{c}{Model properties} &  & \\multicolumn{2}{c}{Accuracy [\\%]} \\\\ \\cmidrule(lr){3-4}  \\cmidrule(lr){7-9} \\cmidrule(l){11-12} \n",
    "    & & ave.              & max.             &  &                       &  Size {[}MB{]}   & \\# Layers   & \\# Weights   &  & Top 1       & Top 5      \\\\ \\midrule\"\"\"\n",
    "    latex_footer = r\"\"\"\n",
    "    \\bottomrule\n",
    "    \\end{tabular}\n",
    "\\end{table}\n",
    "    \"\"\"\n",
    "\n",
    "    latex_content = \"\"\n",
    "    is_first = True\n",
    "    for model_name, variants in data.items():\n",
    "        if variants:\n",
    "            model_section = f\" \"\n",
    "            for i, variant in enumerate(variants):\n",
    "                variant_name = variant['variant'].replace('_', ' ')  # Replace underscores with spaces\n",
    "                if i == 0:\n",
    "                    if is_first:\n",
    "                        model_section += f\" \\\\multirow{{4}}{{*}}{{\\\\rotatebox[origin=c]{{90}}{{{model_name}}}}}  \"\n",
    "                        model_section += f\"& {variant_name} & {variant['lat_mean']} & {variant['lat_worst']} & & {variant['inf_s']} & {variant['size_mb']} & {variant['layers']} & {variant['params']} & & {variant['prec_1']} & {variant['prec_5']} \\\\\\\\\"\n",
    "                        is_first = False\n",
    "                    else:\n",
    "                        model_section += f\"   \\\\midrule \\n\"\n",
    "                        model_section += f\"    \\\\multirow{{4}}{{*}}{{\\\\rotatebox[origin=c]{{90}}{{{model_name}}}}}  \"\n",
    "                        model_section += f\"& {variant_name} & {variant['lat_mean']} & {variant['lat_worst']} & & {variant['inf_s']} & {variant['size_mb']} & {variant['layers']} & {variant['params']} & & {variant['prec_1']} & {variant['prec_5']} \\\\\\\\\"\n",
    "                   \n",
    "                else:\n",
    "                    model_section += f\"    & {variant_name} & {variant['lat_mean']} & {variant['lat_worst']} & & {variant['inf_s']} & {variant['size_mb']} & {variant['layers']} & {variant['params']} & & {variant['prec_1']} & {variant['prec_5']} \\\\\\\\\"\n",
    "                \n",
    "                model_section += \"\\n\"\n",
    "            latex_content += model_section\n",
    "\n",
    "    full_latex = latex_header_1 + name_titulo +latex_header_2 + latex_content + latex_footer\n",
    "    return full_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_apendix(all_tables_data):\n",
    "\n",
    "    # genera TODAS las tablas presentes en el apendice A de la tesis\n",
    "\n",
    "    for red, data in all_tables_data.items():\n",
    "\n",
    "        latex_header_1 = r\"\"\"\n",
    "    \\begin{table}[t]\n",
    "        \\centering\n",
    "        \\footnotesize\n",
    "        \\caption{Thr \"\"\"\n",
    "        latex_header_2 = r\"\"\"}\n",
    "        \\begin{tabular}{ccccccccccc}\n",
    "        \\hline\n",
    "        \\multicolumn{2}{c}{\\textbf{}} & & \\multicolumn{2}{c}{\\textbf{Vanilla}} & \\multicolumn{2}{c}{\\textbf{TRT fp32}} & \\multicolumn{2}{c}{\\textbf{TRT fp16}} & \\multicolumn{2}{c}{\\textbf{TRT int8}} \\\\ \\hline\n",
    "        \\multicolumn{2}{c}{} & \\textit{\\textbf{Batch Size}} & \\textbf{inf/s} & ±(95 \\%) & \\textbf{inf/s} & ±(95 \\%) & \\textbf{inf/s} & ±(95 \\%) & \\textbf{inf/s} & ±(95 \\%) \\\\ \\hline\"\"\"\n",
    "        latex_footer = r\"\"\"\n",
    "        \\end{tabular}\n",
    "    \\end{table}\n",
    "        \"\"\"\n",
    "\n",
    "        latex_content = \"\"\n",
    "        \n",
    "        for plataforma, optimizations in data.items(): \n",
    "            for batch_size in [1, 32, 64, 128, 256]:\n",
    "                latex_content += \" & \\\\multicolumn{1}{c|}{} & \\\\textit{\\\\textbf{%d}} \" % batch_size\n",
    "                for optimization in ['Vanilla', 'TRT_fp32', 'TRT_fp16', 'TRT_int8']:\n",
    "                    if batch_size in optimizations[optimization]:\n",
    "                        value, error = optimizations[optimization][batch_size]\n",
    "                        latex_content += \"& \\\\textbf{%.1f} & %.1f \" % (value, error)\n",
    "                    else:\n",
    "                        latex_content += \"& - & - \"\n",
    "                latex_content += \"\\\\\\\\ \\n\"\n",
    "            \n",
    "            latex_content += \"    & \\\\multicolumn{1}{c|}{\\\\multirow{-5}{*}{\\\\rotatebox[origin=c]{90}{%s}}} & \\\\textit{\\\\textbf{}} \" % plataforma\n",
    "            latex_content += \"\\\\\\\\ \\\\cline{2-11}\"\n",
    "        \n",
    "        full_latex = latex_header_1 + red + latex_header_2+ latex_content + latex_footer\n",
    "        print(full_latex)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_data(file_content):\n",
    "    models_data = file_content.split('# ')[1:]  # Divide por modelo y batch size, ignorando el primer split que estaría vacío\n",
    "    data_summary = {}\n",
    "    inf_s_data = {}\n",
    "\n",
    "    # Procesar y almacenar inf/s para batch size 256 por separado\n",
    "    best_inf_s = {}\n",
    "    best_bs = {}\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, _ = model_name_batch_size.split(' bs ')\n",
    "        for line in lines:\n",
    "            if '|' in line and 'Model' not in line and not all(char == '-' for char in line.replace('|', '').strip()):\n",
    "                cols = [col.strip() for col in line.split('|')]\n",
    "                if len(cols) > 1:\n",
    "                    variant = cols[1]\n",
    "                    if model_name not in best_inf_s:\n",
    "                            best_inf_s[model_name] = {}\n",
    "                            best_bs[model_name] = {}\n",
    "                    best_inf_s[model_name][variant] = 0.0\n",
    "                    best_bs[model_name][variant] = 0\n",
    "\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "        batch_size = int(batch_size_info.strip())\n",
    "\n",
    "        #if batch_size == 256:\n",
    "        for line in lines:\n",
    "            if '|' in line and 'Model' not in line and not all(char == '-' for char in line.replace('|', '').strip()):\n",
    "                cols = [col.strip() for col in line.split('|')]\n",
    "                if len(cols) > 1:\n",
    "                    variant = cols[1]\n",
    "                    inf_s_str = (cols[2].split(' ')[0].replace('.','')).replace(',','.')\n",
    "                    inf_s = float(inf_s_str)\n",
    "                    if inf_s > best_inf_s[model_name][variant]:\n",
    "                        best_inf_s[model_name][variant]  = inf_s\n",
    "                        best_bs[model_name][variant] = batch_size\n",
    "                        if model_name not in inf_s_data:\n",
    "                            inf_s_data[model_name] = {}\n",
    "                        if batch_size == 256:\n",
    "                            inf_s_data[model_name][variant] = '$'+str(inf_s)+'$'\n",
    "                        else: \n",
    "                            inf_s_data[model_name][variant] = '$'+str(inf_s)+'_{bs= '+str(batch_size)+'}$'\n",
    "\n",
    "    # Procesar datos principales para batch size 1 y añadir inf/s de batch size 256 cuando corresponda\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "        batch_size = int(batch_size_info.strip())\n",
    "\n",
    "        if batch_size == 1:\n",
    "            table_data = [line for line in lines if '|' in line and 'Model' not in line]\n",
    "\n",
    "            data_summary[model_name] = []\n",
    "\n",
    "            for data in table_data:\n",
    "                if not all(char == '-' for char in data.replace('|', '').strip()):\n",
    "                    cols = [col.strip() for col in data.split('|')]\n",
    "                    if len(cols) > 1:\n",
    "                        model_variant = cols[1]\n",
    "                        inf_s = inf_s_data.get(model_name, {}).get(model_variant, 'N/A')  # Get inf/s from bs 256 data if available\n",
    "                        lat_mean = cols[3].split(' / ')[0]\n",
    "                        lat_worst = (cols[3].split(' / ')[1]).split(' ')[0]\n",
    "                        lat_mean = lat_mean.strip()\n",
    "                        lat_worst = lat_worst.strip()\n",
    "                        size_mb = cols[4]\n",
    "                        prec_1 = cols[5]\n",
    "                        prec_5 = cols[6]\n",
    "                        layers = cols[7]\n",
    "                        params = cols[8]\n",
    "\n",
    "                        model_data = {\n",
    "                            'variant': model_variant,\n",
    "                            'inf_s': inf_s,  # Added from bs 256 data\n",
    "                            'lat_mean': lat_mean,\n",
    "                            'lat_worst': lat_worst,\n",
    "                            'size_mb': size_mb.strip(),\n",
    "                            'prec_1': prec_1.strip(),\n",
    "                            'prec_5': prec_5.strip(),\n",
    "                            'layers': layers.strip(),\n",
    "                            'params': params.strip()\n",
    "                        }\n",
    "                        data_summary[model_name].append(model_data)\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_data_for_throughput(file_content):\n",
    "\n",
    "    # la idea de esta funcion es agrupar el throupgut y la confianza en data_summary para cada plataforma, para poder luego hacer el print del grafico de los througputs\n",
    "\n",
    "    models_data = file_content.split('# ')[1:]  # Divide por modelo y batch size, ignorando el primer split que estaría vacío\n",
    "    data_summary = {}\n",
    "\n",
    "    # Procesar datos principales para batch size 1 y añadir inf/s de batch size 256 cuando corresponda\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "        batch_size = int(batch_size_info.strip())\n",
    "\n",
    "        table_data = [line for line in lines if '|' in line and 'Model' not in line]\n",
    "\n",
    "        for data in table_data:\n",
    "            if not all(char == '-' for char in data.replace('|', '').strip()):\n",
    "                cols = [col.strip() for col in data.split('|')]\n",
    "                if len(cols) > 1:\n",
    "                    model_variant = cols[1]\n",
    "                    inf_s_str = (cols[2].split(' ')[0].replace('.','')).replace(',','.')\n",
    "                    inf_s = float(inf_s_str)\n",
    "                    confianza_str_minus = (cols[2].split(' ')[3].replace('.','')).replace(',','.').replace('-','')\n",
    "                    confianza_str_plus = (cols[2].split(' ')[2].replace('.','')).replace(',','.').replace('+','')\n",
    "                    confianza = max(float(confianza_str_minus),float(confianza_str_plus))\n",
    "\n",
    "                    if model_name not in data_summary:\n",
    "                        data_summary[model_name] = {}\n",
    "                    if model_variant not in data_summary[model_name]:\n",
    "                        data_summary[model_name][model_variant] = {}\n",
    "                    data_summary[model_name][model_variant][batch_size] = inf_s, confianza\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_thr_data_for_apendix_tab(datas):\n",
    "\n",
    "    #la idea de esta funcion es juntar los datos sacados por el parse parse_markdown_data_for_throughput(file_content) de todos las plataformas y juntarlas en un solo arreglo de datos\n",
    "    #para generar luego las tablas mostradas en el apendice de la tesis\n",
    "\n",
    "    datos_agrupados = {}\n",
    "    # Iterar sobre los datos originales y reorganizarlos\n",
    "    for plataforma, data in datas.items():\n",
    "        for red, optimizaciones in data.items():\n",
    "            for optimizacion, batch_sizes in optimizaciones.items():\n",
    "                for batch_size, valores in batch_sizes.items():\n",
    "                    equipo = f'{plataforma}'\n",
    "                    if red not in datos_agrupados:\n",
    "                        datos_agrupados[red] = {}\n",
    "                    if equipo not in datos_agrupados[red]:\n",
    "                        datos_agrupados[red][equipo] = {}\n",
    "                    if optimizacion not in datos_agrupados[red][equipo]:\n",
    "                        datos_agrupados[red][equipo][optimizacion] = {}\n",
    "                    datos_agrupados[red][equipo][optimizacion][batch_size] = valores\n",
    "\n",
    "    # Mostrar el resultado\n",
    "    return datos_agrupados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_latency(data):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Configuración de tamaño de fuente global\n",
    "    plt.rcParams.update({'font.size': 14})  # Puedes ajustar el tamaño aquí\n",
    "\n",
    "    networks = list(data.keys())  # Networks as the categories\n",
    "    variants = [entry['variant'] for entry in data['mobilenet']]  # Assuming all have the same variants\n",
    "\n",
    "    # Construct a dictionary for lat_mean values, indexed by network and variant\n",
    "    lat_means = {network: {entry['variant']: float(entry['lat_mean']) for entry in entries} for network, entries in data.items()}\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(5, 3.5),tight_layout=True)  # Ajustar el tamaño del gráfico aquí\n",
    "    width = 0.2  # Bar width, más delgado para hacerlo más compacto\n",
    "\n",
    "    # Positioning each bar for each variant within the group\n",
    "    for i, variant in enumerate(variants):\n",
    "        means = [lat_means[network][variant] for network in networks]\n",
    "        ax.bar([x + i * width for x in range(len(networks))], means, width, label=variant)\n",
    "\n",
    "    #ax.set_xlabel('Network')\n",
    "    ax.set_ylabel('Latencia [ms]')\n",
    "    ax.set_title(name_titulo)\n",
    "    ax.set_xticks([x + width * (len(variants) - 1) / 2 for x in range(len(networks))])\n",
    "    ax.set_xticklabels(networks, rotation=20, ha='right')  # Rotar etiquetas y ajustar alineación\n",
    "    ax.legend(title='Optimización')\n",
    "\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.5', color='grey')\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')\n",
    "    ax.minorticks_on()\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'latency_{name}.pdf', format='pdf',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_throughput(data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.rcParams.update({'font.size': 14})  # Puedes ajustar el tamaño aquí\n",
    "    for network_name, variants in data.items():\n",
    "        plt.figure(figsize=(5, 3.5)).tight_layout()\n",
    "        for variant_name, batch_sizes in variants.items():\n",
    "            batch_sizes_sorted = sorted(batch_sizes.items())  # Ordenar los datos por batch size\n",
    "            batch_sizes, performances = zip(*[(batch_size, perf[0]) for batch_size, perf in batch_sizes_sorted]) \n",
    "            plt.plot(batch_sizes, performances, label=variant_name, marker='o')\n",
    "        plt.title(f'{name_titulo}, {network_name}')\n",
    "        plt.xlabel('Batch Size')\n",
    "        plt.ylabel('Throughput [inf/s]')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "        plt.minorticks_on()\n",
    "        plt.savefig(f'througput_{name}_{network_name}.pdf', format='pdf',bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path a archivo .md que contiene las tablas con resultados experimentales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre y lee el archivo\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = file.read()\n",
    "\n",
    "data_all = parse_markdown_data(data)\n",
    "data_throughput = parse_markdown_data_for_throughput(data)\n",
    "with open('../outputs/table_outputs/rtx3060/rtx3060_dynamic_batch.md', 'r', encoding='utf-8') as file:\n",
    "    md_content_rtx3060 = file.read()\n",
    "with open('../outputs/table_outputs/rtx2060/RTX2060MaxQ_dynamic_op.md', 'r', encoding='utf-8') as file:\n",
    "    md_content_rtx2060 = file.read()\n",
    "with open('../outputs/table_outputs/jetson_xavier_agx/xavier_agx_dynamic.md', 'r', encoding='utf-8') as file:\n",
    "    md_content_xavier_agx = file.read()\n",
    "with open('../outputs/table_outputs/jetson_orin_nano/orin_nano_dynamic_op.md', 'r', encoding='utf-8') as file:\n",
    "    md_content_orin_nano = file.read()\n",
    "with open('../outputs/table_outputs/jetson_orin_agx/orin_agx_dynamic_op.md', 'r', encoding='utf-8') as file:\n",
    "    md_content_orin_agx = file.read()\n",
    "# Parse the markdown content\n",
    "#data = parse_markdown_data(md_content)\n",
    "\n",
    "data_rtx3060 = parse_markdown_data_for_throughput(md_content_rtx3060)\n",
    "data_rtx2060 = parse_markdown_data_for_throughput(md_content_rtx2060)\n",
    "data_xavier_agx = parse_markdown_data_for_throughput(md_content_xavier_agx)\n",
    "data_orin_nano = parse_markdown_data_for_throughput(md_content_orin_nano)\n",
    "data_orin_agx = parse_markdown_data_for_throughput(md_content_orin_agx)\n",
    "\n",
    "#print(data)\n",
    "#print(data_throughput)\n",
    "\n",
    "data_apenidx = parse_thr_data_for_apendix_tab({'RTX 3060':data_rtx3060,'RTX 2060':data_rtx2060,'xavier agx':data_xavier_agx,'orin nano':data_orin_nano,'orin agx':data_orin_agx})\n",
    "\n",
    "print(data_apenidx)\n",
    "\n",
    "generate_latex_table_apendix(data_apenidx)\n",
    "#for model_data in parsed_data.items():\n",
    "#    for variants in model_data[1]:\n",
    "#        print(model_data[0], variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar tabla LaTex en para el escrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = generate_latex_table(data_all)\n",
    "print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS\n",
    "\n",
    "## Latencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_network_latency(data_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_network_throughput(data_throughput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
