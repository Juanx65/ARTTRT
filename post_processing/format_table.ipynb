{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALISIS DE RESULTADOS\n",
    "\n",
    "## globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../outputs/table_outputs/jetson_orin_agx/jetson_orin_agx_dynamic_batch.md'\n",
    "name = 'orin_agx'\n",
    "name_titulo = 'Jetson Orin AGX'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table(data):\n",
    "    latex_header = r\"\"\"\n",
    "\\begin{table}[]\n",
    "    \\centering\n",
    "    \\footnotesize\n",
    "    \\caption{Jetson Orin AGX}\n",
    "    \\begin{tabular}{@{}clccccccccccc@{}}\n",
    "    \\toprule\n",
    "    & & \\multicolumn{2}{c}{Latency {[}ms{]}} &  & Thr. {[}inf/s{]} &  \\multicolumn{3}{c}{Model properties} &  & \\multicolumn{2}{c}{Accuracy [\\%]} \\\\ \\cmidrule(lr){3-4}  \\cmidrule(lr){7-9} \\cmidrule(l){11-12} \n",
    "    & & ave.              & max.             &  &                       &  Size {[}MB{]}   & \\# Layers   & \\# Weights   &  & Top 1       & Top 5      \\\\ \\midrule\"\"\"\n",
    "    latex_footer = r\"\"\"\n",
    "    \\bottomrule\n",
    "    \\end{tabular}\n",
    "\\end{table}\n",
    "    \"\"\"\n",
    "\n",
    "    latex_content = \"\"\n",
    "    is_first = True\n",
    "    for model_name, variants in data.items():\n",
    "        if variants:\n",
    "            model_section = f\" \"\n",
    "            for i, variant in enumerate(variants):\n",
    "                variant_name = variant['variant'].replace('_', ' ')  # Replace underscores with spaces\n",
    "                if i == 0:\n",
    "                    if is_first:\n",
    "                        model_section += f\" \\\\multirow{{4}}{{*}}{{\\\\rotatebox[origin=c]{{90}}{{{model_name}}}}}  \"\n",
    "                        model_section += f\"& {variant_name} & {variant['lat_mean']} & {variant['lat_worst']} & & {variant['inf_s']} & {variant['size_mb']} & {variant['layers']} & {variant['params']} & & {variant['prec_1']} & {variant['prec_5']} \\\\\\\\\"\n",
    "                        is_first = False\n",
    "                    else:\n",
    "                        model_section += f\"   \\\\midrule \\n\"\n",
    "                        model_section += f\"    \\\\multirow{{4}}{{*}}{{\\\\rotatebox[origin=c]{{90}}{{{model_name}}}}}  \"\n",
    "                        model_section += f\"& {variant_name} & {variant['lat_mean']} & {variant['lat_worst']} & & {variant['inf_s']} & {variant['size_mb']} & {variant['layers']} & {variant['params']} & & {variant['prec_1']} & {variant['prec_5']} \\\\\\\\\"\n",
    "                   \n",
    "                else:\n",
    "                    model_section += f\"    & {variant_name} & {variant['lat_mean']} & {variant['lat_worst']} & & {variant['inf_s']} & {variant['size_mb']} & {variant['layers']} & {variant['params']} & & {variant['prec_1']} & {variant['prec_5']} \\\\\\\\\"\n",
    "                \n",
    "                model_section += \"\\n\"\n",
    "            latex_content += model_section\n",
    "\n",
    "    full_latex = latex_header + latex_content + latex_footer\n",
    "    return full_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_data(file_content):\n",
    "    models_data = file_content.split('# ')[1:]  # Divide por modelo y batch size, ignorando el primer split que estaría vacío\n",
    "    data_summary = {}\n",
    "    inf_s_data = {}\n",
    "\n",
    "    # Procesar y almacenar inf/s para batch size 256 por separado\n",
    "    best_inf_s = {}\n",
    "    best_bs = {}\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, _ = model_name_batch_size.split(' bs ')\n",
    "        for line in lines:\n",
    "            if '|' in line and 'Model' not in line and not all(char == '-' for char in line.replace('|', '').strip()):\n",
    "                cols = [col.strip() for col in line.split('|')]\n",
    "                if len(cols) > 1:\n",
    "                    variant = cols[1]\n",
    "                    if model_name not in best_inf_s:\n",
    "                            best_inf_s[model_name] = {}\n",
    "                            best_bs[model_name] = {}\n",
    "                    best_inf_s[model_name][variant] = 0.0\n",
    "                    best_bs[model_name][variant] = 0\n",
    "\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "        batch_size = int(batch_size_info.strip())\n",
    "\n",
    "        #if batch_size == 256:\n",
    "        for line in lines:\n",
    "            if '|' in line and 'Model' not in line and not all(char == '-' for char in line.replace('|', '').strip()):\n",
    "                cols = [col.strip() for col in line.split('|')]\n",
    "                if len(cols) > 1:\n",
    "                    variant = cols[1]\n",
    "                    inf_s_str = (cols[2].split(' ')[0].replace('.','')).replace(',','.')\n",
    "                    inf_s = float(inf_s_str)\n",
    "                    if inf_s > best_inf_s[model_name][variant]:\n",
    "                        best_inf_s[model_name][variant]  = inf_s\n",
    "                        best_bs[model_name][variant] = batch_size\n",
    "                        if model_name not in inf_s_data:\n",
    "                            inf_s_data[model_name] = {}\n",
    "                        if batch_size == 256:\n",
    "                            inf_s_data[model_name][variant] = '$'+str(inf_s)+'$'\n",
    "                        else: \n",
    "                            inf_s_data[model_name][variant] = '$'+str(inf_s)+'_{bs= '+str(batch_size)+'}$'\n",
    "\n",
    "    # Procesar datos principales para batch size 1 y añadir inf/s de batch size 256 cuando corresponda\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "        batch_size = int(batch_size_info.strip())\n",
    "\n",
    "        if batch_size == 1:\n",
    "            table_data = [line for line in lines if '|' in line and 'Model' not in line]\n",
    "\n",
    "            data_summary[model_name] = []\n",
    "\n",
    "            for data in table_data:\n",
    "                if not all(char == '-' for char in data.replace('|', '').strip()):\n",
    "                    cols = [col.strip() for col in data.split('|')]\n",
    "                    if len(cols) > 1:\n",
    "                        model_variant = cols[1]\n",
    "                        inf_s = inf_s_data.get(model_name, {}).get(model_variant, 'N/A')  # Get inf/s from bs 256 data if available\n",
    "                        lat_mean = cols[3].split(' / ')[0]\n",
    "                        lat_worst = (cols[3].split(' / ')[1]).split(' ')[0]\n",
    "                        lat_mean = lat_mean.strip()\n",
    "                        lat_worst = lat_worst.strip()\n",
    "                        size_mb = cols[4]\n",
    "                        prec_1 = cols[5]\n",
    "                        prec_5 = cols[6]\n",
    "                        layers = cols[7]\n",
    "                        params = cols[8]\n",
    "\n",
    "                        model_data = {\n",
    "                            'variant': model_variant,\n",
    "                            'inf_s': inf_s,  # Added from bs 256 data\n",
    "                            'lat_mean': lat_mean,\n",
    "                            'lat_worst': lat_worst,\n",
    "                            'size_mb': size_mb.strip(),\n",
    "                            'prec_1': prec_1.strip(),\n",
    "                            'prec_5': prec_5.strip(),\n",
    "                            'layers': layers.strip(),\n",
    "                            'params': params.strip()\n",
    "                        }\n",
    "                        data_summary[model_name].append(model_data)\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_data_for_throughput(file_content):\n",
    "    models_data = file_content.split('# ')[1:]  # Divide por modelo y batch size, ignorando el primer split que estaría vacío\n",
    "    data_summary = {}\n",
    "\n",
    "    # Procesar datos principales para batch size 1 y añadir inf/s de batch size 256 cuando corresponda\n",
    "    for model_section in models_data:\n",
    "        lines = model_section.split('\\n')\n",
    "        model_name_batch_size = lines[0].strip()\n",
    "        model_name, batch_size_info = model_name_batch_size.split(' bs ')\n",
    "        batch_size = int(batch_size_info.strip())\n",
    "\n",
    "        table_data = [line for line in lines if '|' in line and 'Model' not in line]\n",
    "\n",
    "        for data in table_data:\n",
    "            if not all(char == '-' for char in data.replace('|', '').strip()):\n",
    "                cols = [col.strip() for col in data.split('|')]\n",
    "                if len(cols) > 1:\n",
    "                    model_variant = cols[1]\n",
    "                    inf_s_str = (cols[2].split(' ')[0].replace('.','')).replace(',','.')\n",
    "                    inf_s = float(inf_s_str)\n",
    "\n",
    "                    if model_name not in data_summary:\n",
    "                        data_summary[model_name] = {}\n",
    "                    if model_variant not in data_summary[model_name]:\n",
    "                        data_summary[model_name][model_variant] = {}\n",
    "                    data_summary[model_name][model_variant][batch_size] = inf_s\n",
    "\n",
    "    return data_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_latency(data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    networks = list(data.keys())  # Networks as the categories\n",
    "    variants = [entry['variant'] for entry in data['mobilenet']]  # Assuming all have the same variants\n",
    "\n",
    "    # Construct a dictionary for lat_mean values, indexed by network and variant\n",
    "    lat_means = {network: {entry['variant']: float(entry['lat_mean']) for entry in entries} for network, entries in data.items()}\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    width = 0.15  # Bar width\n",
    "\n",
    "    # Positioning each bar for each variant within the group\n",
    "    for i, variant in enumerate(variants):\n",
    "        means = [lat_means[network][variant] for network in networks]\n",
    "        ax.bar([x + i * width for x in range(len(networks))], means, width, label=variant)\n",
    "\n",
    "    ax.set_xlabel('Network', fontweight='bold')\n",
    "    ax.set_ylabel('Latency [ms]', fontweight='bold')\n",
    "    ax.set_title(f'Mean Latency {name_titulo}')\n",
    "    ax.set_xticks([x + width * (len(variants) - 1) / 2 for x in range(len(networks))])\n",
    "    #ax.set_xticklabels(networks, rotation=20)\n",
    "    ax.set_xticklabels(networks, fontweight='bold')\n",
    "    ax.legend(title='Optimization')\n",
    "\n",
    "    ax.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "    ax.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "    ax.minorticks_on()  # Activa las marcas menores\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.savefig(f'latency_{name}.pdf', format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_throughput(data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    for network_name, variants in data.items():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        for variant_name, batch_sizes in variants.items():\n",
    "            batch_sizes_sorted = sorted(batch_sizes.items())  # Ordenar los datos por batch size\n",
    "            batch_sizes, performances = zip(*batch_sizes_sorted)\n",
    "            plt.plot(batch_sizes, performances, label=variant_name, marker='o')\n",
    "        plt.title(f'Inference Throughput {network_name}', fontweight='bold')\n",
    "        plt.xlabel('Batch Size', fontweight='bold')\n",
    "        plt.ylabel('Inference Throughput [inf/s]', fontweight='bold')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='grey')  # Ajusta la grilla principal\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='lightgrey')  # Ajusta la grilla secundaria\n",
    "        plt.minorticks_on()\n",
    "        plt.savefig(f'througput_{name}_{network_name}.pdf', format='pdf')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Path a archivo .md que contiene las tablas con resultados experimentales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abre y lee el archivo\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    md_content = file.read()\n",
    "# Parse the markdown content\n",
    "data = parse_markdown_data(md_content)\n",
    "\n",
    "data_throughput = parse_markdown_data_for_throughput(md_content)\n",
    "\n",
    "#print(data)\n",
    "#print(data_throughput)\n",
    "\n",
    "#for model_data in parsed_data.items():\n",
    "#    for variants in model_data[1]:\n",
    "#        print(model_data[0], variants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar tabla LaTex en para el escrito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_table = generate_latex_table(data)\n",
    "#print(latex_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICOS\n",
    "\n",
    "## Latencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_network_latency(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_network_throughput(data_throughput)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
