 
# mobilenet bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  56,2  +4,2 -4,7 |  17.8 / 25.3    +1.4 -1.4 |  13.6      | 71.40                | 90.64               | 104     | 3487816    |
| TRT_fp32        |  178,7  +28,0 -36,6 |   5.6 / 7.7     +1.0 -1.0 |  14.4      | 71.34                | 90.62               | 57      | 3469760    |
| TRT_fp16        |  272,3  +44,6 -59,2 |   3.7 / 6.0     +0.7 -0.7 |  8.3       | 71.26                | 90.66               | 58      | 3469760    |
| TRT_int8        |  343,8  +48,2 -61,2 |   2.9 / 5.4     +0.5 -0.4 |  5.5       | 70.80                | 90.32               | 57      | 3469760    |
 
# mobilenet bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  227,4  +2,1 -2,1 | 140.7 / 142.7   +1.3 -1.3 |  13.6      | 71.43                | 90.65               | 109     | 3487816    |
| TRT_fp32        |  567,1  +102,7 -141,2 |  56.4 / 80.2    +12.5 -11.2 |  15.4      | 71.37                | 90.65               | 78      | 3469760    |
| TRT_fp16        |  717,8  +220,3 -408,2 |  44.6 / 58.6    +19.7 -16.2 |  8.6       | 71.31                | 90.67               | 76      | 3469760    |
| TRT_int8        |  944,7  +184,3 -260,9 |  33.9 / 39.5    +8.2 -7.3 |  5.0       | 70.91                | 90.30               | 57      | 3469760    |
 
# mobilenet bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  230,6  +2,2 -2,2 | 277.6 / 282.8   +2.6 -2.6 |  13.6      | 71.43                | 90.65               | 109     | 3487816    |
| TRT_fp32        |  593,4  +64,5 -77,1 | 107.9 / 125.8   +13.2 -12.4 |  15.4      | 71.37                | 90.65               | 78      | 3469760    |
| TRT_fp16        |  801,7  +154,8 -218,2 |  79.8 / 93.2    +19.1 -17.1 |  8.6       | 71.31                | 90.67               | 76      | 3469760    |
| TRT_int8        |  1.155,6  +356,1 -662,2 |  55.4 / 69.6    +24.7 -20.2 |  5.0       | 70.91                | 90.30               | 57      | 3469760    |
 
# mobilenet bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  232,5  +1,8 -1,8 | 550.5 / 558.6   +4.2 -4.2 |  13.6      | 71.43                | 90.65               | 109     | 3487816    |
| TRT_fp32        |  648,1  +68,3 -81,3 | 197.5 / 221.7   +23.3 -22.0 |  15.4      | 71.37                | 90.65               | 78      | 3469760    |
| TRT_fp16        |  940,4  +113,3 -138,4 | 136.1 / 155.5   +18.6 -17.5 |  8.6       | 71.31                | 90.67               | 76      | 3469760    |
| TRT_int8        |  1.238,1  +128,7 -152,6 | 103.4 / 114.8   +12.0 -11.3 |  5.0       | 70.91                | 90.30               | 57      | 3469760    |
 
# mobilenet bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  228,4  +27,1 -33,0 | 1120.7 / 1442.5  +150.9 -141.5 |  13.6      | 71.11                | 90.50               | 109     | 3487816    |
| TRT_fp32        |  687,9  +31,0 -33,3 | 372.2 / 390.2   +17.6 -17.2 |  15.4      | 71.05                | 90.50               | 78      | 3469760    |
| TRT_fp16        |  1.089,0  +67,0 -73,8 | 235.1 / 249.3   +15.4 -14.9 |  8.6       | 70.99                | 90.52               | 76      | 3469760    |
| TRT_int8        |  1.505,6  +166,2 -199,4 | 170.0 / 193.1   +21.1 -19.9 |  5.0       | 70.62                | 90.17               | 57      | 3469760    |
 
# resnet50 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  47,5  +2,7 -3,0 |  21.1 / 26.1    +1.3 -1.3 |  97.8      | 80.18                | 95.04               | 126     | 25530472   |
| TRT_fp32        |  80,5  +1,7 -1,8 |  12.4 / 15.5    +0.3 -0.3 |  100.4     | 80.12                | 95.04               | 59      | 25502912   |
| TRT_fp16        |  143,5  +5,7 -6,0 |   7.0 / 8.5     +0.3 -0.3 |  51.3      | 80.20                | 95.02               | 60      | 25502912   |
| TRT_int8        |  201,1  +28,4 -36,1 |   5.0 / 7.5     +0.8 -0.8 |  27.1      | 79.54                | 94.90               | 58      | 25493504   |
 
# resnet50 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  104,6  +0,6 -0,6 | 305.8 / 308.5   +1.8 -1.8 |  97.8      | 80.25                | 95.05               | 131     | 25530472   |
| TRT_fp32        |  271,8  +3,9 -4,0 | 117.8 / 120.7   +1.7 -1.7 |  99.6      | 80.19                | 95.03               | 98      | 25502912   |
| TRT_fp16        |  492,6  +63,0 -78,0 |  65.0 / 84.8    +9.5 -8.9 |  50.4      | 80.21                | 94.99               | 99      | 25502912   |
| TRT_int8        |  635,8  +164,9 -270,1 |  50.3 / 68.6    +17.6 -15.0 |  26.6      | 77.90                | 95.15               | 58      | 25493504   |
 
# resnet50 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  110,8  +0,6 -0,6 | 577.4 / 582.4   +3.2 -3.2 |  97.8      | 80.23                | 95.03               | 131     | 25530472   |
| TRT_fp32        |  283,3  +4,4 -4,5 | 225.9 / 232.4   +3.5 -3.5 |  99.6      | 80.19                | 95.03               | 98      | 25502912   |
| TRT_fp16        |  518,0  +40,9 -46,5 | 123.5 / 137.9   +10.6 -10.2 |  50.4      | 80.21                | 94.99               | 99      | 25502912   |
| TRT_int8        |  696,8  +133,1 -186,7 |  91.9 / 116.6   +21.7 -19.4 |  26.6      | 77.90                | 95.15               | 58      | 25493504   |
 
# resnet50 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  113,3  +0,4 -0,4 | 1130.2 / 1136.1  +4.3 -4.2 |  97.8      | 80.23                | 95.03               | 131     | 25530472   |
| TRT_fp32        |  287,0  +5,3 -5,4 | 446.0 / 454.2   +8.4 -8.3 |  99.6      | 80.19                | 95.03               | 98      | 25502912   |
| TRT_fp16        |  531,1  +42,9 -48,8 | 241.0 / 273.1   +21.2 -20.3 |  50.4      | 80.21                | 94.99               | 99      | 25502912   |
| TRT_int8        |  814,7  +109,9 -137,9 | 157.1 / 186.6   +24.5 -22.8 |  26.6      | 77.90                | 95.15               | 58      | 25493504   |
 
# resnet50 bs 256
 
CUDA is available.
Memory exceeded (97752 KB available) by experiments/main/main.py -v --batch_size 256 --dataset datasets/subdataset_val/val --network resnet50 --less --engine weights/best.engine --model_version Vanilla --log_dir outputs/log/log_vanilla_resnet50_bs_256_PM0  , terminating PID 467313
Memory exceeded (96840 KB available) by experiments/main/main.py -v --batch_size 256 --dataset datasets/subdataset_val/val --network resnet50 -trt --engine weights/best_fp32.engine --less --non_verbose --model_version TRT_fp32 --log_dir outputs/log/log_fp32_resnet50_bs_256_PM0  , terminating PID 468642
Memory exceeded (96336 KB available) by experiments/main/main.py -v --batch_size 256 --dataset datasets/subdataset_val/val --network resnet50 -trt --engine weights/best_fp16.engine --less --non_verbose --model_version TRT_fp16 --log_dir outputs/log/log_fp16_resnet50_bs_256_PM0  , terminating PID 468647
| TRT_int8        |  912,0  +58,9 -65,2 | 280.7 / 293.7   +19.4 -18.7 |  26.6      | 77.73                | 95.07               | 58      | 25493504   |
 
# resnet152 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  17,5  +0,7 -0,8 |  57.1 / 69.4    +2.5 -2.4 |  230.5     | 81.72                | 96.28               | 364     | 60117096   |
| TRT_fp32        |  63,5  +3,3 -3,5 |  15.8 / 18.6    +0.9 -0.8 |  232.8     | 81.74                | 96.28               | 161     | 60040384   |
| TRT_fp16        |  65,5  +1,1 -1,2 |  15.3 / 16.9    +0.3 -0.3 |  117.6     | 81.76                | 96.24               | 161     | 60040384   |
| TRT_int8        |  93,5  +5,9 -6,6 |  10.7 / 12.5    +0.7 -0.7 |  61.3      | 81.44                | 96.04               | 160     | 60030976   |
 
# resnet152 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  47,9  +0,1 -0,1 | 668.2 / 670.7   +2.0 -2.0 |  230.5     | 81.77                | 96.27               | 369     | 60117096   |
| TRT_fp32        |  119,3  +0,9 -0,9 | 268.1 / 271.9   +1.9 -1.9 |  232.0     | 81.79                | 96.27               | 296     | 60040384   |
| TRT_fp16        |  232,2  +2,0 -2,0 | 137.8 / 140.9   +1.2 -1.2 |  116.5     | 81.83                | 96.21               | 303     | 60040384   |
| TRT_int8        |  436,4  +26,6 -29,3 |  73.3 / 90.8    +4.8 -4.6 |  60.9      | 79.21                | 95.93               | 160     | 60030976   |
 
# resnet152 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  50,6  +0,1 -0,1 | 1264.0 / 1267.5  +3.7 -3.7 |  230.5     | 81.77                | 96.27               | 369     | 60117096   |
| TRT_fp32        |  125,4  +1,0 -1,1 | 510.5 / 518.4   +4.3 -4.3 |  232.0     | 81.79                | 96.27               | 296     | 60040384   |
| TRT_fp16        |  242,5  +2,4 -2,4 | 263.9 / 268.9   +2.6 -2.6 |  116.5     | 81.83                | 96.21               | 303     | 60040384   |
| TRT_int8        |  458,8  +20,9 -22,5 | 139.5 / 152.7   +6.7 -6.5 |  60.9      | 79.21                | 95.93               | 160     | 60030976   |
 
# resnet152 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  51,3  +0,1 -0,1 | 2495.0 / 2502.3  +5.4 -5.4 |  230.5     | 81.77                | 96.27               | 369     | 60117096   |
| TRT_fp32        |  128,1  +1,5 -1,6 | 999.3 / 1013.1  +12.2 -12.1 |  232.0     | 81.79                | 96.27               | 296     | 60040384   |
| TRT_fp16        |  246,2  +2,2 -2,2 | 519.9 / 526.3   +4.6 -4.6 |  116.5     | 81.83                | 96.21               | 303     | 60040384   |
| TRT_int8        |  469,6  +26,3 -28,8 | 272.5 / 296.9   +16.2 -15.7 |  60.9      | 79.21                | 95.93               | 160     | 60030976   |
 
# resnet152 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency (ms) +-95%|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  47,7  +3,8 -4,4 | 5367.0 / 5617.4  +470.6 -451.1 |  230.5     | 81.70                | 96.20               | 369     | 60117096   |
| TRT_fp32        |  126,5  +1,1 -1,2 | 2023.2 / 2036.6  +18.6 -18.5 |  232.0     | 81.72                | 96.20               | 296     | 60040384   |
| TRT_fp16        |  245,7  +1,9 -1,9 | 1041.8 / 1050.3  +8.1 -8.0 |  116.5     | 81.76                | 96.13               | 303     | 60040384   |
| TRT_int8        |  476,3  +19,1 -20,3 | 537.4 / 561.8   +22.5 -22.0 |  60.9      | 79.13                | 95.85               | 160     | 60030976   |
