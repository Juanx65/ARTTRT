VANILLA: Iniciando el monitoreo de la GPU con PID 30645
CUDA is available.
|  Model          |Latency-all (ms)|Latency-model (ms)|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)|
|-----------------|----------------|------------------|-----------|----------------------|---------------------|
| yolo            |  1.6 / 3.7  |  1.2 / 2.9  | 5.3     | 65.96                | 86.55               |
VANILLA ENDS
TRT FP32: Iniciando el monitoreo de la GPU con PID 30825
CUDA is available.
|  Model          |Latency-all (ms)|Latency-model (ms)|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)|
|-----------------|----------------|------------------|-----------|----------------------|---------------------|
| yolo            |  0.8 / 2.0  |  0.4 / 1.3  | 12.8    | 65.96                | 86.55               |
ONNX metrics
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[I] ==== TensorRT Network ====
    Name: Unnamed Network 0 | Explicit Batch Network
    
    ---- 1 Network Input(s) ----
    {images [dtype=float32, shape=(1, 3, 224, 224)]}
    
    ---- 1 Network Output(s) ----
    {outputs [dtype=float32, shape=(1, 1000)]}
    
    ---- 322 Layer(s) ----
Number of parameters in the model: 2715880
ENGINE metrics
[I] Loading bytes from /home/juan/Documents/ArtTRT/weights/best_fp32.engine
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[I] ==== TensorRT Engine ====
    Name: Unnamed Network 0 | Explicit Batch Engine
    
    ---- 1 Engine Input(s) ----
    {images [dtype=float32, shape=(1, 3, 224, 224)]}
    
    ---- 1 Engine Output(s) ----
    {outputs [dtype=float32, shape=(1, 1000)]}
    
    ---- Memory ----
    Device Memory: 2107392 bytes
    
    ---- 1 Profile(s) (2 Tensor(s) Each) ----
    - Profile: 0
        Tensor: images           (Input), Index: 0 | Shapes: min=(1, 3, 224, 224), opt=(1, 3, 224, 224), max=(1, 3, 224, 224)
        Tensor: outputs         (Output), Index: 1 | Shape: (1, 1000)
    
    ---- 81 Layer(s) ----
CUDA is available.
Total de parametros en el engine: 2711472
TRT FP32 ENDS
TRT FP16: Iniciando el monitoreo de la GPU con PID 30997
CUDA is available.
|  Model          |Latency-all (ms)|Latency-model (ms)|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)|
|-----------------|----------------|------------------|-----------|----------------------|---------------------|
| yolo            |  0.7 / 1.9  |  0.3 / 1.0  | 6.1     | 65.96                | 86.55               |
ONNX metrics
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[I] ==== TensorRT Network ====
    Name: Unnamed Network 0 | Explicit Batch Network
    
    ---- 1 Network Input(s) ----
    {images [dtype=float32, shape=(1, 3, 224, 224)]}
    
    ---- 1 Network Output(s) ----
    {outputs [dtype=float32, shape=(1, 1000)]}
    
    ---- 322 Layer(s) ----
Number of parameters in the model: 2715880
ENGINE metrics
[I] Loading bytes from /home/juan/Documents/ArtTRT/weights/best_fp16.engine
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[I] ==== TensorRT Engine ====
    Name: Unnamed Network 0 | Explicit Batch Engine
    
    ---- 1 Engine Input(s) ----
    {images [dtype=float32, shape=(1, 3, 224, 224)]}
    
    ---- 1 Engine Output(s) ----
    {outputs [dtype=float32, shape=(1, 1000)]}
    
    ---- Memory ----
    Device Memory: 1053696 bytes
    
    ---- 1 Profile(s) (2 Tensor(s) Each) ----
    - Profile: 0
        Tensor: images           (Input), Index: 0 | Shapes: min=(1, 3, 224, 224), opt=(1, 3, 224, 224), max=(1, 3, 224, 224)
        Tensor: outputs         (Output), Index: 1 | Shape: (1, 1000)
    
    ---- 59 Layer(s) ----
CUDA is available.
Total de parametros en el engine: 2711472
TRT FP16 ENDS
TRT INT8: Iniciando el monitoreo de la GPU con PID 31167
CUDA is available.
|  Model          |Latency-all (ms)|Latency-model (ms)|size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)|
|-----------------|----------------|------------------|-----------|----------------------|---------------------|
| yolo            |  0.7 / 1.9  |  0.3 / 1.4  | 5.2     | 63.38                | 84.63               |
ONNX metrics
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[W] onnx2trt_utils.cpp:374: Your ONNX model has been generated with INT64 weights, while TensorRT does not natively support INT64. Attempting to cast down to INT32.
[I] ==== TensorRT Network ====
    Name: Unnamed Network 0 | Explicit Batch Network
    
    ---- 1 Network Input(s) ----
    {images [dtype=float32, shape=(1, 3, 224, 224)]}
    
    ---- 1 Network Output(s) ----
    {outputs [dtype=float32, shape=(1, 1000)]}
    
    ---- 322 Layer(s) ----
Number of parameters in the model: 2715880
ENGINE metrics
[I] Loading bytes from /home/juan/Documents/ArtTRT/weights/best_int8.engine
[W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See "Lazy Loading" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading
[I] ==== TensorRT Engine ====
    Name: Unnamed Network 0 | Explicit Batch Engine
    
    ---- 1 Engine Input(s) ----
    {images [dtype=float32, shape=(1, 3, 224, 224)]}
    
    ---- 1 Engine Output(s) ----
    {outputs [dtype=float32, shape=(1, 1000)]}
    
    ---- Memory ----
    Device Memory: 727552 bytes
    
    ---- 1 Profile(s) (2 Tensor(s) Each) ----
    - Profile: 0
        Tensor: images           (Input), Index: 0 | Shapes: min=(1, 3, 224, 224), opt=(1, 3, 224, 224), max=(1, 3, 224, 224)
        Tensor: outputs         (Output), Index: 1 | Shape: (1, 1000)
    
    ---- 51 Layer(s) ----
CUDA is available.
Total de parametros en el engine: 2711472
TRT INT8 ENDS
