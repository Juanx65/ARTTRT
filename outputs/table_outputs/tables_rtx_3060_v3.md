# mobilenet bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  415,1  +80,2 -113,1 |   2.4 / 98.6    +0.6 -0.5 |    2.0 / 98.2    |  13.6      | 72.02                | 90.63               | 104     | 3487816    |
| TRT fp32        |  1.108,2  +112,5 -132,7 |   0.9 / 1.7     +0.1 -0.1 |    0.5 / 1.0     |  14.2      | 72.02                | 90.62               | 57      | 3469760    |
| TRT fp16        |  1.309,5  +167,3 -207,2 |   0.8 / 2.1     +0.1 -0.1 |    0.4 / 1.1     |  8.3       | 71.99                | 90.63               | 58      | 3469760    |
| TRT int8        |  1.428,8  +194,1 -244,1 |   0.7 / 1.8     +0.1 -0.1 |    0.3 / 1.0     |  6.0       | 71.44                | 90.38               | 57      | 3469760    |
 
# mobilenet bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.250,3  +13,8 -14,0 |  25.6 / 27.0    +0.3 -0.3 |   19.1 / 19.4    |  13.6      | 72.02                | 90.63               | 104     | 3487816    |
| TRT fp32        |  2.476,9  +55,1 -57,1 |  12.9 / 14.5    +0.3 -0.3 |    6.4 / 6.6     |  14.4      | 72.03                | 90.63               | 58      | 3469760    |
| TRT fp16        |  3.220,2  +83,1 -86,5 |   9.9 / 11.6    +0.3 -0.3 |    3.4 / 3.6     |  8.9       | 72.01                | 90.64               | 58      | 3469760    |
| TRT int8        |  3.728,8  +98,8 -102,9 |   8.6 / 9.7     +0.2 -0.2 |    2.1 / 2.3     |  5.6       | 71.42                | 90.32               | 56      | 3469760    |
 
# mobilenet bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.285,8  +9,3 -9,4 |  49.8 / 50.9    +0.4 -0.4 |   37.2 / 37.5    |  13.6      | 72.02                | 90.63               | 104     | 3487816    |
| TRT fp32        |  2.587,8  +34,3 -35,0 |  24.7 / 25.6    +0.3 -0.3 |   12.2 / 12.5    |  14.6      | 72.03                | 90.63               | 58      | 3469760    |
| TRT fp16        |  3.375,7  +64,6 -66,5 |  19.0 / 20.2    +0.4 -0.4 |    6.4 / 6.7     |  8.9       | 72.01                | 90.64               | 58      | 3469760    |
| TRT int8        |  3.908,6  +83,6 -86,4 |  16.4 / 17.5    +0.4 -0.4 |    3.8 / 4.0     |  5.5       | 71.46                | 90.34               | 56      | 3469760    |
 
# mobilenet bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.309,8  +7,5 -7,6 |  97.7 / 99.5    +0.6 -0.6 |   73.1 / 73.4    |  13.6      | 72.06                | 90.64               | 104     | 3487816    |
| TRT fp32        |  2.647,1  +27,2 -27,6 |  48.4 / 49.8    +0.5 -0.5 |   23.7 / 24.0    |  14.4      | 72.06                | 90.64               | 58      | 3469760    |
| TRT fp16        |  3.484,1  +53,5 -54,8 |  36.7 / 39.7    +0.6 -0.6 |   12.1 / 12.3    |  8.8       | 72.04                | 90.64               | 58      | 3469760    |
| TRT int8        |  4.049,5  +64,5 -66,1 |  31.6 / 32.7    +0.5 -0.5 |    7.0 / 7.2     |  5.5       | 71.49                | 90.38               | 56      | 3469760    |
 
# mobilenet bs 256
 
CUDA is available.
No se encontró el número de parametros
No se encontró el número de capas
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.318,8  +5,2 -5,2 | 194.1 / 195.7   +0.8 -0.8 |  145.3 / 145.7   |  13.6      | 72.06                | 90.64               | 0       | 0          |
| TRT fp32*       |  2.676,1  +24,2 -24,6 |  95.7 / 97.7    +0.9 -0.9 |   46.9 / 47.1    |  14.4      | 72.06                | 90.64               | 58      | 3469760    |
| TRT fp16*       |  3.519,0  +40,9 -41,7 |  72.7 / 74.3    +0.9 -0.9 |   23.8 / 24.2    |  9.1       | 72.03                | 90.65               | 58      | 3469760    |

# resnet18 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  584,8  +84,5 -108,0 |   1.7 / 4.4     +0.3 -0.3 |    1.3 / 3.9     |  44.7      | 69.76                | 89.08               | 53      | 11684712   |
| TRT fp32        |  775,0  +50,0 -55,4 |   1.3 / 2.0     +0.1 -0.1 |    0.9 / 1.3     |  66.6      | 69.75                | 89.09               | 28      | 11678912   |
| TRT fp16        |  1.311,6  +162,5 -199,8 |   0.8 / 1.7     +0.1 -0.1 |    0.4 / 0.9     |  25.1      | 69.77                | 89.10               | 27      | 11678912   |
| TRT int8        |  1.562,4  +233,0 -300,5 |   0.6 / 1.6     +0.1 -0.1 |    0.2 / 0.7     |  13.3      | 69.56                | 88.91               | 25      | 11669504   |
 
# resnet18 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.329,4  +16,7 -17,0 |  24.1 / 25.6    +0.3 -0.3 |   17.6 / 17.9    |  44.7      | 69.77                | 89.09               | 53      | 11684712   |
| TRT fp32        |  1.805,2  +29,3 -30,0 |  17.7 / 19.5    +0.3 -0.3 |   11.2 / 11.6    |  45.3      | 69.76                | 89.09               | 26      | 11678912   |
| TRT fp16        |  3.086,6  +72,4 -75,0 |  10.4 / 11.3    +0.2 -0.2 |    3.9 / 4.0     |  23.8      | 69.77                | 89.09               | 27      | 11678912   |
| TRT int8        |  3.879,9  +111,4 -116,5 |   8.2 / 9.9     +0.2 -0.2 |    1.8 / 1.9     |  12.5      | 69.51                | 88.98               | 24      | 11669504   |
 
# resnet18 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.400,8  +11,0 -11,1 |  45.7 / 46.9    +0.4 -0.4 |   33.1 / 33.5    |  44.7      | 69.77                | 89.08               | 53      | 11684712   |
| TRT fp32        |  1.882,7  +21,1 -21,4 |  34.0 / 35.3    +0.4 -0.4 |   21.4 / 21.7    |  45.3      | 69.76                | 89.09               | 26      | 11678912   |
| TRT fp16        |  3.238,8  +64,5 -66,4 |  19.8 / 22.0    +0.4 -0.4 |    7.2 / 7.5     |  23.8      | 69.77                | 89.10               | 27      | 11678912   |
| TRT int8        |  4.084,4  +80,8 -83,3 |  15.7 / 16.8    +0.3 -0.3 |    3.1 / 3.3     |  12.3      | 69.60                | 88.99               | 24      | 11669504   |
 
# resnet18 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.443,2  +8,1 -8,1 |  88.7 / 90.0    +0.5 -0.5 |   64.1 / 64.5    |  44.7      | 69.80                | 89.10               | 53      | 11684712   |
| TRT fp32        |  1.939,2  +14,7 -14,9 |  66.0 / 67.5    +0.5 -0.5 |   41.4 / 41.8    |  45.4      | 69.80                | 89.11               | 29      | 11678912   |
| TRT fp16        |  3.396,9  +49,4 -50,5 |  37.7 / 39.9    +0.6 -0.6 |   13.1 / 13.7    |  23.8      | 69.79                | 89.11               | 27      | 11678912   |
| TRT int8        |  4.221,8  +69,6 -71,3 |  30.3 / 31.8    +0.5 -0.5 |    5.7 / 5.9     |  12.4      | 69.56                | 89.04               | 24      | 11669504   |
 
# resnet18 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  1.446,4  +7,4 -7,5 | 177.0 / 178.9   +0.9 -0.9 |  128.1 / 128.4   |  44.7      | 69.80                | 89.10               | 53      | 11684712   |
| TRT fp32        |  1.943,3  +13,3 -13,4 | 131.7 / 133.6   +0.9 -0.9 |   82.9 / 83.1    |  45.6      | 69.80                | 89.11               | 41      | 11678912   |
| TRT fp16        |  3.428,9  +50,5 -51,6 |  74.7 / 77.3    +1.1 -1.1 |   25.6 / 25.8    |  23.8      | 69.79                | 89.11               | 27      | 11678912   |
 
# resnet34 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  362,0  +28,2 -32,0 |   2.8 / 4.7     +0.2 -0.2 |    2.4 / 4.3     |  83.3      | 73.29                | 91.42               | 93      | 21789160   |
| TRT fp32        |  497,2  +20,3 -21,6 |   2.0 / 2.6     +0.1 -0.1 |    1.6 / 1.9     |  128.1     | 73.29                | 91.42               | 44      | 21779648   |
| TRT fp16        |  1.034,9  +94,7 -109,8 |   1.0 / 1.7     +0.1 -0.1 |    0.6 / 0.9     |  44.4      | 73.31                | 91.43               | 42      | 21779648   |
| TRT int8        |  1.298,7  +155,3 -189,4 |   0.8 / 1.7     +0.1 -0.1 |    0.4 / 1.0     |  23.1      | 73.24                | 91.40               | 41      | 21770240   |
 
# resnet34 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  859,1  +5,0 -5,0 |  37.2 / 39.3    +0.2 -0.2 |   30.9 / 31.3    |  83.3      | 73.30                | 91.42               | 93      | 21789160   |
| TRT fp32        |  1.162,3  +14,1 -14,3 |  27.5 / 29.4    +0.3 -0.3 |   21.1 / 21.3    |  83.9      | 73.31                | 91.42               | 42      | 21779648   |
| TRT fp16        |  2.475,1  +50,9 -52,5 |  12.9 / 14.4    +0.3 -0.3 |    6.4 / 6.7     |  43.0      | 73.32                | 91.42               | 43      | 21779648   |
| TRT int8        |  3.324,5  +87,4 -91,0 |   9.6 / 11.1    +0.3 -0.3 |    3.1 / 3.3     |  22.2      | 73.28                | 91.43               | 40      | 21770240   |
 
# resnet34 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  908,9  +3,4 -3,5 |  70.4 / 71.2    +0.3 -0.3 |   58.0 / 58.4    |  83.3      | 73.30                | 91.42               | 93      | 21789160   |
| TRT fp32        |  1.222,7  +9,2 -9,3 |  52.3 / 53.6    +0.4 -0.4 |   39.8 / 40.0    |  84.1      | 73.31                | 91.43               | 42      | 21779648   |
| TRT fp16        |  2.610,6  +35,0 -35,7 |  24.5 / 25.6    +0.3 -0.3 |   12.0 / 12.2    |  42.9      | 73.32                | 91.43               | 43      | 21779648   |
| TRT int8        |  3.509,6  +80,3 -83,2 |  18.2 / 20.4    +0.4 -0.4 |    5.7 / 5.9     |  22.1      | 73.24                | 91.39               | 40      | 21770240   |
 
# resnet34 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  931,4  +3,6 -3,6 | 137.4 / 139.0   +0.5 -0.5 |  113.0 / 113.6   |  83.3      | 73.34                | 91.43               | 93      | 21789160   |
| TRT fp32        |  1.251,2  +9,7 -9,9 | 102.3 / 104.1   +0.8 -0.8 |   77.7 / 78.4    |  84.2      | 73.35                | 91.43               | 66      | 21779648   |
| TRT fp16        |  2.693,0  +28,6 -29,1 |  47.5 / 48.5    +0.5 -0.5 |   22.9 / 23.3    |  42.9      | 73.35                | 91.43               | 43      | 21779648   |
| TRT int8        |  3.648,0  +56,9 -58,2 |  35.1 / 36.6    +0.6 -0.6 |   10.4 / 10.6    |  22.1      | 73.25                | 91.36               | 40      | 21770240   |
 
# resnet34 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  933,7  +3,6 -3,6 | 274.2 / 276.6   +1.1 -1.1 |  225.6 / 226.3   |  83.3      | 73.34                | 91.42               | 93      | 21789160   |
| TRT fp32        |  1.251,7  +6,8 -6,9 | 204.5 / 206.0   +1.1 -1.1 |  155.6 / 156.4   |  84.2      | 73.35                | 91.43               | 72      | 21779648   |
| TRT fp16        |  2.713,4  +31,2 -31,7 |  94.3 / 96.2    +1.1 -1.1 |   45.2 / 45.7    |  43.0      | 73.35                | 91.43               | 43      | 21779648   |
 
# resnet50 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  305,5  +27,0 -31,2 |   3.3 / 6.1     +0.3 -0.3 |    2.9 / 5.5     |  97.8      | 80.34                | 95.12               | 126     | 25530472   |
| TRT fp32        |  451,5  +17,8 -18,9 |   2.2 / 3.1     +0.1 -0.1 |    1.8 / 2.2     |  108.0     | 80.34                | 95.13               | 79      | 25502912   |
| TRT fp16        |  912,2  +68,4 -77,1 |   1.1 / 1.9     +0.1 -0.1 |    0.7 / 1.1     |  50.6      | 80.35                | 95.14               | 60      | 25502912   |
| TRT int8        |  1.131,0  +113,0 -133,1 |   0.9 / 1.8     +0.1 -0.1 |    0.5 / 1.0     |  28.1      | 78.57                | 94.95               | 58      | 25493504   |
 
# resnet50 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  535,7  +1,5 -1,5 |  59.7 / 60.1    +0.2 -0.2 |   53.4 / 53.8    |  97.8      | 80.35                | 95.13               | 126     | 25530472   |
| TRT fp32        |  1.022,4  +9,0 -9,1 |  31.3 / 32.2    +0.3 -0.3 |   24.9 / 25.3    |  98.6      | 80.35                | 95.13               | 59      | 25502912   |
| TRT fp16        |  2.037,7  +33,9 -34,8 |  15.7 / 16.3    +0.3 -0.3 |    9.2 / 9.4     |  50.5      | 80.35                | 95.13               | 60      | 25502912   |
| TRT int8        |  2.907,5  +81,3 -84,9 |  11.0 / 12.7    +0.3 -0.3 |    4.5 / 4.7     |  27.0      | 78.58                | 94.96               | 57      | 25493504   |
 
# resnet50 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  555,0  +0,7 -0,7 | 115.3 / 115.7   +0.1 -0.1 |  103.0 / 103.4   |  97.8      | 80.35                | 95.13               | 126     | 25530472   |
| TRT fp32        |  1.063,4  +6,7 -6,7 |  60.2 / 61.1    +0.4 -0.4 |   47.7 / 48.1    |  98.7      | 80.35                | 95.13               | 65      | 25502912   |
| TRT fp16        |  2.130,1  +26,3 -26,8 |  30.0 / 31.9    +0.4 -0.4 |   17.5 / 17.7    |  50.6      | 80.35                | 95.12               | 60      | 25502912   |
| TRT int8        |  3.066,7  +55,7 -57,3 |  20.9 / 22.8    +0.4 -0.4 |    8.3 / 8.6     |  26.9      | 78.61                | 94.98               | 58      | 25493504   |
 
# resnet50 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  568,1  +0,5 -0,5 | 225.3 / 225.8   +0.2 -0.2 |  201.0 / 201.4   |  97.8      | 80.39                | 95.13               | 126     | 25530472   |
| TRT fp32        |  1.084,0  +5,1 -5,1 | 118.1 / 119.4   +0.6 -0.6 |   93.5 / 94.0    |  98.9      | 80.38                | 95.14               | 86      | 25502912   |
| TRT fp16        |  2.194,7  +20,1 -20,4 |  58.3 / 59.4    +0.5 -0.5 |   33.7 / 33.9    |  50.7      | 80.39                | 95.13               | 60      | 25502912   |
| TRT int8        |  3.158,1  +44,2 -45,2 |  40.5 / 42.2    +0.6 -0.6 |   15.9 / 16.3    |  27.3      | 79.90                | 95.10               | 58      | 25493504   |
 
# resnet50 bs 256
 
CUDA is available.
No se encontró el número de parametros
No se encontró el número de capas
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  577,6  +1,4 -1,4 | 443.2 / 444.0   +1.1 -1.1 |  394.9 / 395.6   |  97.8      | 80.39                | 95.13               | 0       | 0          |
| TRT fp32 *      |  1.090,7  +5,8 -5,8 | 234.7 / 237.4   +1.3 -1.3 |  186.0 / 186.8   |  98.9      | 80.39                | 95.13               | 98      | 25502912   |
| TRT fp16 *      |  2.217,8  +14,9 -15,1 | 115.4 / 116.9   +0.8 -0.8 |   66.5 / 66.8    |  50.5      | 80.42                | 95.14               | 69      | 25502912   |

# resnet101 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  181,7  +11,7 -13,0 |   5.5 / 8.3     +0.4 -0.4 |    5.2 / 8.0     |  170.5     | 81.67                | 95.66               | 245     | 44496488   |
| TRT fp32        |  267,8  +5,5 -5,6 |   3.7 / 4.3     +0.1 -0.1 |    3.4 / 3.7     |  210.4     | 81.67                | 95.67               | 164     | 44442816   |
| TRT fp16        |  615,1  +31,9 -34,6 |   1.6 / 2.3     +0.1 -0.1 |    1.2 / 1.5     |  86.8      | 81.66                | 95.67               | 111     | 44442816   |
| TRT int8        |  853,6  +59,4 -66,4 |   1.2 / 2.3     +0.1 -0.1 |    0.8 / 1.6     |  46.7      | 79.90                | 95.59               | 109     | 44433408   |
 
# resnet101 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  334,8  +0,7 -0,7 |  95.6 / 96.0    +0.2 -0.2 |   89.3 / 89.7    |  170.5     | 81.68                | 95.66               | 245     | 44496488   |
| TRT fp32        |  625,3  +2,6 -2,6 |  51.2 / 52.3    +0.2 -0.2 |   44.8 / 45.1    |  171.2     | 81.67                | 95.67               | 125     | 44442816   |
| TRT fp16        |  1.476,0  +19,8 -20,3 |  21.7 / 22.8    +0.3 -0.3 |   15.2 / 15.5    |  86.7      | 81.67                | 95.67               | 111     | 44442816   |
| TRT int8        |  2.303,7  +44,6 -45,9 |  13.9 / 15.0    +0.3 -0.3 |    7.4 / 7.7     |  45.9      | 79.91                | 95.57               | 109     | 44433408   |
 
# resnet101 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  347,8  +0,3 -0,3 | 184.0 / 184.5   +0.1 -0.1 |  171.7 / 172.0   |  170.5     | 81.68                | 95.66               | 245     | 44496488   |
| TRT fp32        |  663,6  +2,9 -2,9 |  96.4 / 97.3    +0.4 -0.4 |   84.1 / 84.5    |  171.3     | 81.67                | 95.67               | 164     | 44442816   |
| TRT fp16        |  1.554,4  +15,4 -15,6 |  41.2 / 42.6    +0.4 -0.4 |   28.6 / 28.9    |  86.8      | 81.67                | 95.68               | 111     | 44442816   |
| TRT int8        |  2.435,5  +35,0 -35,8 |  26.3 / 27.9    +0.4 -0.4 |   13.7 / 14.0    |  45.6      | 80.00                | 95.59               | 109     | 44433408   |
 
# resnet101 bs 128
 
CUDA is available.
No se encontró el número de parametros
No se encontró el número de capas
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  354,4  +0,9 -0,9 | 361.2 / 361.7   +0.9 -0.9 |  336.9 / 337.4   |  170.5     | 81.71                | 95.66               | 0       | 0          |
| TRT fp32*       |  674,3  +2,6 -2,6 | 189.8 / 190.6   +0.7 -0.7 |  165.5 / 166.0   |  171.5     | 81.70                | 95.67               | 188     | 44442816   |
| TRT fp16*        |  1.587,4  +10,0 -10,1 |  80.6 / 81.7    +0.5 -0.5 |   56.0 / 56.5    |  86.7      | 81.71                | 95.68               | 168     | 44442816   |

# resnet101 bs 256
 
CUDA is available.
No se encontró el número de parametros
No se encontró el número de capas
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  365,3  +0,7 -0,7 | 700.7 / 701.5   +1.3 -1.3 |  652.5 / 653.0   |  170.5     | 81.71                | 95.66               | 0       | 0          |
| TRT fp32*       |  679,1  +2,4 -2,4 | 377.0 / 378.4   +1.3 -1.3 |  328.6 / 329.4   |  171.5     | 81.70                | 95.67               | 200     | 44442816   |
| TRT fp16*       |  1.609,6  +10,6 -10,7 | 159.0 / 160.6   +1.1 -1.1 |  110.2 / 111.0   |  86.6      | 81.71                | 95.68               | 147     | 44442816   |

# resnet152 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  129,6  +9,0 -10,1 |   7.7 / 11.6    +0.6 -0.6 |    7.4 / 11.1    |  230.5     | 82.34                | 95.92               | 364     | 60117096   |
| TRT fp32        |  192,6  +2,5 -2,6 |   5.2 / 5.7     +0.1 -0.1 |    4.8 / 5.2     |  292.7     | 82.34                | 95.92               | 241     | 60040384   |
| TRT fp16        |  468,5  +17,2 -18,2 |   2.1 / 2.8     +0.1 -0.1 |    1.7 / 2.2     |  116.9     | 82.34                | 95.91               | 162     | 60040384   |
| TRT int8        |  671,6  +37,2 -40,6 |   1.5 / 2.4     +0.1 -0.1 |    1.1 / 1.9     |  62.4      | 79.99                | 95.74               | 160     | 60030976   |
 
# resnet152 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  238,3  +0,4 -0,4 | 134.3 / 134.7   +0.2 -0.2 |  128.0 / 128.4   |  230.5     | 82.35                | 95.93               | 364     | 60117096   |
| TRT fp32        |  449,3  +1,6 -1,6 |  71.2 / 71.9    +0.2 -0.2 |   64.9 / 65.2    |  230.9     | 82.34                | 95.92               | 218     | 60040384   |
| TRT fp16        |  1.137,7  +13,7 -13,9 |  28.1 / 29.1    +0.3 -0.3 |   21.6 / 22.0    |  116.7     | 82.34                | 95.90               | 162     | 60040384   |
| TRT int8        |  1.883,0  +31,2 -32,0 |  17.0 / 18.0    +0.3 -0.3 |   10.5 / 10.7    |  61.4      | 80.02                | 95.80               | 160     | 60030976   |
 
# resnet152 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  247,8  +0,1 -0,1 | 258.3 / 258.8   +0.1 -0.1 |  246.0 / 246.5   |  230.5     | 82.35                | 95.93               | 364     | 60117096   |
| TRT fp32        |  480,1  +0,7 -0,7 | 133.3 / 133.8   +0.2 -0.2 |  121.0 / 121.4   |  231.1     | 82.34                | 95.92               | 257     | 60040384   |
| TRT fp16        |  1.198,1  +9,9 -10,1 |  53.4 / 54.9    +0.4 -0.4 |   40.9 / 41.3    |  116.6     | 82.33                | 95.90               | 165     | 60040384   |
| TRT int8        |  1.985,6  +27,4 -28,0 |  32.2 / 34.3    +0.5 -0.4 |   19.7 / 19.9    |  61.1      | 81.78                | 95.84               | 160     | 60030976   |
 
# resnet152 bs 128
 
CUDA is available.
No se encontró el número de parametros
No se encontró el número de capas
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  251,7  +0,1 -0,1 | 508.6 / 509.0   +0.2 -0.2 |  484.3 / 484.7   |  230.5     | 82.39                | 95.93               | 0       | 0          |
| TRT fp32*       |  486,7  +0,6 -0,6 | 263.0 / 263.5   +0.3 -0.3 |  238.7 / 239.2   |  231.3     | 82.38                | 95.92               | 302     | 60040384   |
| TRT fp16*       |  1.231,0  +6,2 -6,3 | 104.0 / 104.8   +0.5 -0.5 |   79.3 / 79.8    |  116.8     | 82.37                | 95.91               | 276     | 60040384   |
# resnet152 bs 256
 
CUDA is available.
No se encontró el número de parametros
No se encontró el número de capas
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  259,7  +0,1 -0,1 | 985.9 / 986.5   +0.3 -0.3 |  937.6 / 938.0   |  230.5     | 82.38                | 95.93               | 0       | 0          |
| TRT fp32*       |  489,9  +0,6 -0,6 | 522.6 / 523.2   +0.6 -0.6 |  474.3 / 474.8   |  231.3     | 82.38                | 95.92               | 296     | 60040384   |
| TRT fp16*       |  1.247,7  +5,0 -5,0 | 205.2 / 206.6   +0.8 -0.8 |  156.3 / 156.7   |  116.9     | 82.37                | 95.91               | 276     | 60040384   |
