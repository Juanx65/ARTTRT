# mobilenet bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  63,1  +3,7 -4,1 |  15.8 / 32.9    +1.0 -1.0 |   15.2 / 31.8    |  13.6      | 72.02                | 90.62               | 104     | 3487816    |
| TRT_fp32        |  188,3  +25,9 -32,6 |   5.3 / 10.7    +0.8 -0.8 |    4.3 / 9.5     |  14.3      | 72.01                | 90.62               | 57      | 3469760    |
| TRT_fp16        |  277,5  +40,0 -51,1 |   3.6 / 12.3    +0.6 -0.6 |    2.8 / 10.0    |  9.5       | 71.98                | 90.63               | 58      | 3469760    |
 
# mobilenet bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  283,3  +3,7 -3,8 | 112.9 / 120.8   +1.5 -1.5 |  107.8 / 113.2   |  13.6      | 72.03                | 90.63               | 109     | 3487816    |
| TRT_fp32        |  632,9  +107,4 -144,3 |  50.6 / 76.1    +10.3 -9.4 |   44.4 / 70.1    |  14.9      | 72.03                | 90.64               | 79      | 3469760    |
| TRT_fp16        |  792,4  +232,1 -414,0 |  40.4 / 49.9    +16.7 -13.9 |   34.3 / 42.5    |  8.6       | 72.04                | 90.66               | 73      | 3469760    |
 
# mobilenet bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  287,1  +5,1 -5,2 | 222.9 / 239.2   +4.0 -4.0 |  213.7 / 225.7   |  13.6      | 72.03                | 90.63               | 109     | 3487816    |
| TRT_fp32        |  672,4  +101,0 -130,4 |  95.2 / 131.8   +16.8 -15.5 |   84.2 / 121.5   |  14.9      | 72.03                | 90.64               | 79      | 3469760    |
| TRT_fp16        |  919,4  +228,2 -363,8 |  69.6 / 91.4    +23.0 -19.7 |   58.5 / 78.7    |  8.6       | 72.04                | 90.66               | 73      | 3469760    |
 
# mobilenet bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  290,2  +5,2 -5,3 | 441.1 / 468.6   +8.0 -7.9 |  424.3 / 438.1   |  13.6      | 72.07                | 90.64               | 109     | 3487816    |
| TRT_fp32        |  724,2  +91,5 -113,0 | 176.8 / 236.4   +25.6 -23.9 |  156.9 / 216.1   |  14.9      | 72.06                | 90.65               | 79      | 3469760    |
| TRT_fp16        |  1.013,7  +142,5 -180,7 | 126.3 / 165.3   +20.6 -19.1 |  105.1 / 144.9   |  8.6       | 72.07                | 90.67               | 73      | 3469760    |
 
# mobilenet bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  292,8  +2,9 -3,0 | 874.2 / 899.9   +8.8 -8.8 |  842.5 / 856.5   |  13.6      | 72.07                | 90.64               | 109     | 3487816    |
| TRT_fp32        |  756,1  +64,1 -73,5 | 338.6 / 413.9   +31.4 -30.0 |  298.7 / 373.5   |  14.9      | 72.06                | 90.65               | 79      | 3469760    |
| TRT_fp16        |  1.143,8  +112,1 -131,6 | 223.8 / 270.9   +24.3 -23.1 |  183.5 / 231.7   |  8.6       | 72.07                | 90.67               | 73      | 3469760    |
 
# resnet18 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  78,6  +9,0 -10,9 |  12.7 / 21.3    +1.6 -1.5 |   12.0 / 17.9    |  44.7      | 69.75                | 89.07               | 53      | 11684712   |
| TRT_fp32        |  165,5  +20,4 -25,0 |   6.0 / 9.0     +0.8 -0.8 |    5.0 / 7.1     |  46.5      | 69.76                | 89.08               | 26      | 11678912   |
| TRT_fp16        |  302,2  +53,1 -72,2 |   3.3 / 6.6     +0.7 -0.6 |    2.5 / 5.2     |  24.4      | 69.76                | 89.09               | 27      | 11678912   |
 
# resnet18 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  378,0  +12,4 -13,1 |  84.7 / 96.6    +2.9 -2.8 |   79.5 / 90.3    |  44.7      | 69.77                | 89.07               | 58      | 11684712   |
| TRT_fp32        |  587,5  +80,5 -101,4 |  54.5 / 79.8    +8.6 -8.0 |   48.3 / 74.6    |  45.6      | 69.76                | 89.08               | 47      | 11678912   |
| TRT_fp16        |  837,6  +250,1 -453,1 |  38.2 / 47.8    +16.3 -13.4 |   32.1 / 40.4    |  23.1      | 69.77                | 89.08               | 36      | 11678912   |
 
# resnet18 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  408,1  +14,5 -15,4 | 156.8 / 168.1   +5.8 -5.7 |  147.4 / 153.7   |  44.7      | 69.77                | 89.08               | 58      | 11684712   |
| TRT_fp32        |  614,5  +77,9 -96,3 | 104.1 / 139.0   +15.1 -14.1 |   93.0 / 128.9   |  45.6      | 69.76                | 89.08               | 47      | 11678912   |
| TRT_fp16        |  988,0  +273,9 -469,3 |  64.8 / 83.5    +24.8 -20.9 |   53.7 / 71.4    |  23.1      | 69.77                | 89.08               | 36      | 11678912   |
 
# resnet18 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  406,0  +9,4 -9,7 | 315.3 / 332.8   +7.5 -7.4 |  297.8 / 308.7   |  44.7      | 69.81                | 89.09               | 58      | 11684712   |
| TRT_fp32        |  637,4  +64,6 -76,3 | 200.8 / 242.7   +22.7 -21.5 |  179.8 / 223.1   |  45.6      | 69.80                | 89.10               | 47      | 11678912   |
| TRT_fp16        |  1.085,1  +153,9 -195,6 | 118.0 / 160.8   +19.5 -18.0 |   97.0 / 138.0   |  23.1      | 69.81                | 89.10               | 36      | 11678912   |
 
# resnet18 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  409,1  +10,9 -11,4 | 625.8 / 654.1   +17.2 -16.9 |  590.8 / 608.4   |  44.7      | 69.81                | 89.09               | 58      | 11684712   |
| TRT_fp32        |  657,8  +46,7 -52,3 | 389.2 / 441.9   +29.7 -28.6 |  348.6 / 401.7   |  45.6      | 69.80                | 89.10               | 47      | 11678912   |
| TRT_fp16        |  1.221,6  +120,7 -141,9 | 209.6 / 252.8   +23.0 -21.8 |  169.0 / 209.0   |  23.1      | 69.81                | 89.10               | 36      | 11678912   |
 
# resnet34 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  61,3  +2,6 -2,8 |  16.3 / 28.7    +0.7 -0.7 |   15.7 / 27.5    |  83.3      | 73.31                | 91.42               | 93      | 21789160   |
| TRT_fp32        |  105,5  +7,3 -8,2 |   9.5 / 12.0    +0.7 -0.7 |    8.3 / 9.6     |  85.1      | 73.31                | 91.43               | 42      | 21779648   |
| TRT_fp16        |  183,6  +24,3 -30,4 |   5.4 / 7.7     +0.8 -0.8 |    4.4 / 6.2     |  43.7      | 73.30                | 91.44               | 43      | 21779648   |
 
# resnet34 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  235,4  +7,2 -7,6 | 135.9 / 142.7   +4.3 -4.2 |  130.5 / 136.2   |  83.3      | 73.31                | 91.42               | 98      | 21789160   |
| TRT_fp32        |  375,1  +6,3 -6,4 |  85.3 / 99.8    +1.4 -1.4 |   79.0 / 94.3    |  84.6      | 73.32                | 91.43               | 84      | 21779648   |
| TRT_fp16        |  647,9  +127,0 -180,2 |  49.4 / 74.2    +12.0 -10.7 |   43.2 / 66.9    |  42.4      | 73.32                | 91.45               | 76      | 21779648   |
 
# resnet34 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  257,4  +5,7 -5,9 | 248.7 / 262.4   +5.6 -5.5 |  237.6 / 245.0   |  83.3      | 73.31                | 91.42               | 98      | 21789160   |
| TRT_fp32        |  397,6  +10,4 -10,8 | 161.0 / 168.0   +4.3 -4.3 |  149.6 / 153.7   |  84.6      | 73.32                | 91.43               | 84      | 21779648   |
| TRT_fp16        |  701,4  +112,1 -147,7 |  91.2 / 137.1   +17.4 -15.9 |   80.1 / 126.6   |  42.4      | 73.32                | 91.45               | 76      | 21779648   |
 
# resnet34 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  256,5  +3,7 -3,8 | 499.0 / 513.1   +7.3 -7.2 |  478.6 / 486.5   |  83.3      | 73.35                | 91.43               | 98      | 21789160   |
| TRT_fp32        |  409,5  +9,3 -9,6 | 312.6 / 338.9   +7.3 -7.2 |  291.5 / 318.9   |  84.6      | 73.35                | 91.43               | 84      | 21779648   |
| TRT_fp16        |  766,5  +94,2 -115,6 | 167.0 / 224.4   +23.4 -21.9 |  146.0 / 203.9   |  42.4      | 73.36                | 91.45               | 76      | 21779648   |
 
# resnet34 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  259,2  +4,3 -4,5 | 987.5 / 1008.9  +16.8 -16.7 |  951.7 / 968.3   |  83.3      | 73.35                | 91.43               | 98      | 21789160   |
| TRT_fp32        |  413,9  +7,9 -8,2 | 618.5 / 661.1   +12.1 -12.0 |  578.1 / 621.3   |  84.6      | 73.35                | 91.43               | 84      | 21779648   |
| TRT_fp16        |  826,5  +68,1 -77,7 | 309.8 / 363.2   +27.8 -26.6 |  269.0 / 319.8   |  42.4      | 73.36                | 91.45               | 76      | 21779648   |
 
# resnet50 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  52,2  +2,3 -2,4 |  19.2 / 35.0    +0.9 -0.8 |   18.5 / 34.0    |  97.8      | 80.34                | 95.13               | 126     | 25530472   |
| TRT_fp32        |  86,0  +7,7 -8,9 |  11.6 / 19.9    +1.1 -1.1 |   10.4 / 18.2    |  100.3     | 80.35                | 95.14               | 59      | 25502912   |
| TRT_fp16        |  149,7  +21,0 -26,6 |   6.7 / 13.8    +1.1 -1.0 |    5.6 / 12.6    |  51.3      | 80.36                | 95.13               | 60      | 25502912   |
 
# resnet50 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  140,0  +1,7 -1,8 | 228.6 / 236.5   +2.8 -2.8 |  222.9 / 228.8   |  97.8      | 80.35                | 95.13               | 131     | 25530472   |
| TRT_fp32        |  314,1  +8,5 -8,9 | 101.9 / 107.0   +2.8 -2.8 |   96.3 / 100.0   |  99.0      | 80.36                | 95.14               | 89      | 25502912   |
| TRT_fp16        |  582,3  +74,6 -92,4 |  55.0 / 88.2    +8.1 -7.5 |   48.8 / 82.9    |  50.0      | 80.37                | 95.13               | 102     | 25502912   |
 
# resnet50 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  150,3  +2,2 -2,2 | 425.9 / 436.7   +6.3 -6.3 |  415.6 / 426.6   |  97.8      | 80.35                | 95.14               | 131     | 25530472   |
| TRT_fp32        |  325,1  +7,0 -7,2 | 196.8 / 209.8   +4.3 -4.3 |  187.5 / 193.6   |  99.0      | 80.36                | 95.14               | 89      | 25502912   |
| TRT_fp16        |  601,9  +69,4 -83,9 | 106.3 / 141.6   +13.9 -13.0 |   95.0 / 131.4   |  50.0      | 80.37                | 95.13               | 102     | 25502912   |
 
# resnet50 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  152,9  +1,3 -1,3 | 836.9 / 849.8   +7.1 -7.1 |  819.2 / 825.4   |  97.8      | 80.38                | 95.14               | 131     | 25530472   |
| TRT_fp32        |  325,7  +6,4 -6,6 | 393.0 / 409.4   +7.9 -7.8 |  372.9 / 381.0   |  99.0      | 80.39                | 95.14               | 89      | 25502912   |
| TRT_fp16        |  616,8  +55,4 -64,0 | 207.5 / 259.4   +20.5 -19.5 |  186.4 / 238.5   |  50.0      | 80.40                | 95.14               | 102     | 25502912   |
 
# resnet50 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  155,6  +0,8 -0,8 | 1645.2 / 1655.7  +8.2 -8.2 | 1613.6 / 1624.1  |  97.8      | 80.39                | 95.14               | 131     | 25530472   |
| TRT_fp32        |  325,5  +4,6 -4,7 | 786.6 / 803.2   +11.3 -11.2 |  748.2 / 762.3   |  99.0      | 80.39                | 95.14               | 89      | 25502912   |
| TRT_fp16        |  623,6  +42,4 -47,3 | 410.5 / 484.5   +30.0 -28.9 |  369.8 / 442.2   |  50.0      | 80.40                | 95.14               | 102     | 25502912   |
 
# resnet101 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  28,5  +0,8 -0,8 |  35.0 / 48.1    +1.0 -1.0 |   34.4 / 47.2    |  170.5     | 81.68                | 95.66               | 245     | 44496488   |
| TRT_fp32        |  51,6  +2,7 -2,9 |  19.4 / 25.9    +1.1 -1.0 |   18.1 / 24.3    |  172.1     | 81.67                | 95.67               | 110     | 44442816   |
| TRT_fp16        |  95,1  +9,1 -10,6 |  10.5 / 17.8    +1.1 -1.1 |    9.3 / 16.6    |  87.4      | 81.67                | 95.65               | 111     | 44442816   |
 
# resnet101 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  88,6  +0,9 -0,9 | 361.1 / 374.1   +3.8 -3.8 |  355.0 / 362.5   |  170.5     | 81.69                | 95.67               | 250     | 44496488   |
| TRT_fp32        |  185,6  +2,0 -2,0 | 172.4 / 178.9   +1.8 -1.8 |  166.2 / 172.3   |  171.8     | 81.68                | 95.67               | 206     | 44442816   |
| TRT_fp16        |  373,6  +8,3 -8,6 |  85.7 / 98.9    +1.9 -1.9 |   79.4 / 92.8    |  86.4      | 81.67                | 95.67               | 192     | 44442816   |
 
# resnet101 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  95,1  +1,0 -1,0 | 673.3 / 684.6   +6.8 -6.8 |  662.4 / 670.4   |  170.5     | 81.68                | 95.67               | 250     | 44496488   |
| TRT_fp32        |  193,2  +3,6 -3,7 | 331.3 / 344.4   +6.3 -6.2 |  319.8 / 328.1   |  171.8     | 81.68                | 95.67               | 206     | 44442816   |
| TRT_fp16        |  391,0  +9,8 -10,2 | 163.7 / 170.6   +4.2 -4.2 |  152.3 / 156.1   |  86.4      | 81.67                | 95.67               | 192     | 44442816   |
 
# resnet101 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  95,9  +0,6 -0,7 | 1335.2 / 1347.4  +9.1 -9.1 | 1315.8 / 1325.0  |  170.5     | 81.71                | 95.67               | 250     | 44496488   |
| TRT_fp32        |  197,2  +2,2 -2,3 | 649.2 / 660.7   +7.5 -7.4 |  628.4 / 636.5   |  171.8     | 81.71                | 95.67               | 206     | 44442816   |
| TRT_fp16        |  399,2  +7,5 -7,7 | 320.7 / 335.4   +6.1 -6.0 |  299.6 / 314.4   |  86.4      | 81.70                | 95.68               | 192     | 44442816   |
 
# resnet101 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  98,3  +0,4 -0,4 | 2603.6 / 2617.8  +10.5 -10.5 | 2570.6 / 2582.0  |  170.5     | 81.71                | 95.67               | 250     | 44496488   |
| TRT_fp32        |  194,4  +1,5 -1,5 | 1316.6 / 1331.2  +10.0 -10.0 | 1278.2 / 1292.5  |  171.8     | 81.71                | 95.67               | 206     | 44442816   |
| TRT_fp16        |  400,0  +5,0 -5,1 | 640.0 / 653.9   +8.1 -8.0 |  599.6 / 606.6   |  86.4      | 81.70                | 95.68               | 192     | 44442816   |
 
# resnet152 bs 1
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  19,8  +0,5 -0,5 |  50.5 / 56.9    +1.2 -1.2 |   49.9 / 56.2    |  230.5     | 82.32                | 95.92               | 364     | 60117096   |
| TRT_fp32        |  58,7  +7,2 -8,8 |  17.0 / 24.6    +2.4 -2.2 |   16.0 / 23.3    |  231.7     | 82.32                | 95.92               | 161     | 60040384   |
| TRT_fp16        |  69,3  +4,9 -5,5 |  14.4 / 21.1    +1.1 -1.1 |   13.2 / 19.6    |  117.4     | 82.33                | 95.91               | 162     | 60040384   |
 
# resnet152 bs 32
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  63,8  +0,4 -0,4 | 501.4 / 514.4   +3.5 -3.5 |  495.1 / 506.5   |  230.5     | 82.34                | 95.93               | 369     | 60117096   |
| TRT_fp32        |  131,7  +1,5 -1,6 | 243.0 / 251.7   +2.9 -2.9 |  236.4 / 243.7   |  231.6     | 82.33                | 95.92               | 308     | 60040384   |
| TRT_fp16        |  254,8  +6,4 -6,6 | 125.6 / 130.3   +3.2 -3.2 |  119.2 / 122.7   |  116.2     | 82.33                | 95.90               | 306     | 60040384   |
 
# resnet152 bs 64
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  68,0  +0,5 -0,5 | 941.1 / 953.6   +7.0 -7.0 |  929.4 / 940.0   |  230.5     | 82.33                | 95.92               | 369     | 60117096   |
| TRT_fp32        |  137,4  +2,0 -2,0 | 465.9 / 477.0   +6.8 -6.7 |  453.6 / 461.7   |  231.6     | 82.33                | 95.92               | 308     | 60040384   |
| TRT_fp16        |  267,5  +5,7 -5,9 | 239.3 / 248.9   +5.2 -5.1 |  227.8 / 233.9   |  116.2     | 82.33                | 95.90               | 306     | 60040384   |
 
# resnet152 bs 128
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  68,3  +0,3 -0,3 | 1874.4 / 1886.0  +9.5 -9.5 | 1853.8 / 1863.2  |  230.5     | 82.37                | 95.93               | 369     | 60117096   |
| TRT_fp32        |  140,3  +1,4 -1,5 | 912.3 / 926.1   +9.5 -9.5 |  891.0 / 899.9   |  231.6     | 82.37                | 95.92               | 308     | 60040384   |
| TRT_fp16        |  271,3  +4,7 -4,9 | 471.8 / 486.8   +8.4 -8.3 |  450.9 / 459.1   |  116.2     | 82.37                | 95.90               | 306     | 60040384   |
 
# resnet152 bs 256
 
CUDA is available.
|  Model          | inf/s +-95% | Latency-all (ms) +-95%|Latency-model (ms) |size (MB)  | accuracy (Prec@1) (%)|accuracy (Prec@5) (%)| #layers | #parameters|
|-----------------|-------------|-----------------------|------------------------|-----------|----------------------|---------------------|---------|------------|
| Vanilla         |  70,0  +0,2 -0,2 | 3655.1 / 3678.1  +12.2 -12.2 | 3621.1 / 3643.4  |  230.5     | 82.37                | 95.93               | 369     | 60117096   |
| TRT_fp32        |  137,5  +0,9 -0,9 | 1861.2 / 1881.5  +11.7 -11.7 | 1822.1 / 1838.2  |  231.6     | 82.37                | 95.92               | 308     | 60040384   |
| TRT_fp16        |  271,9  +2,2 -2,2 | 941.4 / 955.0   +7.6 -7.5 |  902.0 / 912.5   |  116.2     | 82.37                | 95.90               | 306     | 60040384   |
 
